{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fF8ysCfYKgTP"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "We will take the following steps to implement Efficientdet-D0 on our custom data:\n",
    "* Install TensorFlow2 Object Detection Dependencies\n",
    "* Write Custom TensorFlow2 Object Detection Training Configuation\n",
    "* Train Custom TensorFlow2 Object Detection Model\n",
    "* Export Custom TensorFlow2 Object Detection Weights\n",
    "\n",
    "The inference made with our model can be found in the inference folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7EOtpvlLeS0"
   },
   "source": [
    "# Step 1: Install TensorFlow2 Object Detection Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "Requirement already satisfied: gitpython in /anaconda/envs/py38_default/lib/python3.8/site-packages (3.1.24)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from gitpython) (4.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from gitpython) (3.7.4.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/anaconda/envs/py38_default/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gitpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypWGYdPlLRUN",
    "outputId": "64d4d196-f81a-4e85-bc6e-a2650e185855"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from git import Repo\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "models_folder = os.path.join(os.getcwd(), \"models\")\n",
    "\n",
    "# Clone the tensorflow models repository if it doesn't already exist in this folder\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "    while \"models\" in pathlib.Path.cwd().parts:\n",
    "        os.chdir('..')\n",
    "\n",
    "    logging.info(\"The models have already been uploaded. Change working directory to the models folder.\")\n",
    "\n",
    "elif not pathlib.Path('models').exists():\n",
    "    os.mkdir(\"./models\")\n",
    "    repo = Repo.clone_from(\n",
    "        'http://RebSolcia:Clementinabookie18121998!@github.com/tensorflow/models.git',\n",
    "        models_folder,\n",
    "        depth=1,\n",
    "        branch='master',\n",
    "    )\n",
    "\n",
    "    logging.info(\"The models have now been loaded from the tensorflow/models.git repo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.1: PyCoco library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycoco_folder = os.path.join(os.getcwd(), \"pycoco\")\n",
    "\n",
    "# Clone the pycoco repository if it doesn't exist. It is needed to avoid clashes with the TF2API\n",
    "if \"pycoco\" in pathlib.Path.cwd().parts:\n",
    "    while \"pycoco\" in pathlib.Path.cwd().parts:\n",
    "        os.chdir('..')\n",
    "\n",
    "    logging.info(\"The models have already been uploaded. Change working directory to the models folder.\")\n",
    "\n",
    "elif not pathlib.Path('pycoco').exists():\n",
    "    os.mkdir(\"./pycoco\")\n",
    "    repo = Repo.clone_from(\n",
    "        'http://RebSolcia:Clementinabookie18121998!@github.com/cocodataset/cocoapi.git',\n",
    "        pycoco_folder, \n",
    "        branch=\"master\"\n",
    "    )\n",
    "\n",
    "    logging.info(\"The models have now been loaded from the coco repo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps are needed in order to avoid having problems with Pycoco.\n",
    "\n",
    "1. Clone the official repository\n",
    "2. Navigate to the PythonAPI folder and open the setup.py file\n",
    "3. Edit line 12 to be extra_compile_args=[]. The rationale here is to remove the Clang specific arguments, which don’t work on MVCC.\n",
    "\n",
    "4. Run the following line\n",
    "\n",
    "\n",
    "This final command will build and install the package within your current environment, ready to go. To test if the installation succeeded, fire up Python and import it as: import pycocotools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/pycoco/PythonAPI\n",
      "running build_ext\n",
      "skipping 'pycocotools/_mask.c' Cython extension (up-to-date)\n",
      "copying build/lib.linux-x86_64-3.8/pycocotools/_mask.cpython-38-x86_64-linux-gnu.so -> pycocotools\n"
     ]
    }
   ],
   "source": [
    "%cd /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/pycoco/PythonAPI\n",
    "!python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.2: Changes to the Models folder\n",
    "\n",
    "1. Navigate to “./research/object_detection/packages/tf2/” and edit the setup.py file. From the REQUIRED_PACKAGES list, delete the pycocotools reference (line 20). This change will prevent the installation process from trying to reinstall pycocotools from pip, which would fail and abort the whole process.\n",
    "2. Copy this setup.py file to the “./research” folder, replacing the setup.py that was already there.\n",
    "3. Once you're done, run the following line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6QPmVBSlLTzM",
    "outputId": "32e07c91-e6fc-432b-b41a-2885a86f5985",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "Processing /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "Requirement already satisfied: avro-python3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (1.9.2.1)\n",
      "Requirement already satisfied: apache-beam in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (2.33.0)\n",
      "Requirement already satisfied: pillow in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (8.3.1)\n",
      "Requirement already satisfied: lxml in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (4.6.3)\n",
      "Requirement already satisfied: matplotlib in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (3.3.4)\n",
      "Requirement already satisfied: Cython in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (0.29.23)\n",
      "Requirement already satisfied: contextlib2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (21.6.0)\n",
      "Requirement already satisfied: tf-slim in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: six in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (1.15.0)\n",
      "Requirement already satisfied: lvis in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (0.5.3)\n",
      "Requirement already satisfied: scipy in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (1.4.1)\n",
      "Requirement already satisfied: pandas in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (1.2.5)\n",
      "Requirement already satisfied: tf-models-official>=2.5.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: tensorflow_io in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (0.21.0)\n",
      "Requirement already satisfied: keras==2.6.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.4)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n",
      "Requirement already satisfied: tensorflow>=2.5.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.6.1)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.8.0)\n",
      "Requirement already satisfied: opencv-python-headless in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.5.4.58)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: tensorflow-datasets in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.4.0)\n",
      "Requirement already satisfied: pycocotools in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.0.2)\n",
      "Requirement already satisfied: gin-config in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.1)\n",
      "Requirement already satisfied: sacrebleu in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.0.0)\n",
      "Requirement already satisfied: oauth2client in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: tensorflow-addons in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.14.0)\n",
      "Requirement already satisfied: tensorflow-text>=2.5.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: seqeval in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
      "Requirement already satisfied: sentencepiece in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.96)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.28.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=1.21.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.2.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.19.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.32.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (52.0.0.post20210125)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.25.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.53.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.7.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil in /anaconda/envs/py38_default/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.1)\n",
      "Requirement already satisfied: tqdm in /anaconda/envs/py38_default/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.61.2)\n",
      "Requirement already satisfied: certifi in /anaconda/envs/py38_default/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.5.30)\n",
      "Requirement already satisfied: python-slugify in /anaconda/envs/py38_default/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.26.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pandas->object-detection==0.1) (2021.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
      "Requirement already satisfied: clang~=5.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (5.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Collecting h5py~=3.1.0\n",
      "  Using cached h5py-3.1.0-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "Requirement already satisfied: absl-py~=0.10 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.2.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.41.1)\n",
      "Requirement already satisfied: wheel~=0.35 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.36.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.4.3)\n",
      "Collecting numpy>=1.15.4\n",
      "  Using cached numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: gast==0.4.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from apache-beam->object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
      "Requirement already satisfied: pyarrow<5.0.0,>=0.15.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from apache-beam->object-detection==0.1) (4.0.1)\n",
      "Requirement already satisfied: future<1.0.0,>=0.18.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from apache-beam->object-detection==0.1) (0.18.2)\n",
      "Requirement already satisfied: orjson<4.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from apache-beam->object-detection==0.1) (3.6.4)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from apache-beam->object-detection==0.1) (1.7)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from apache-beam->object-detection==0.1) (3.12.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.21.4 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from apache-beam->object-detection==0.1) (1.4.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docopt in /anaconda/envs/py38_default/lib/python3.8/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from lvis->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from lvis->object-detection==0.1) (0.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from lvis->object-detection==0.1) (4.5.3.56)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
      "Requirement already satisfied: portalocker in /anaconda/envs/py38_default/lib/python3.8/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2.3.2)\n",
      "Requirement already satisfied: regex in /anaconda/envs/py38_default/lib/python3.8/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2021.7.6)\n",
      "Requirement already satisfied: colorama in /anaconda/envs/py38_default/lib/python3.8/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.4.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (2.2.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.4.0)\n",
      "Requirement already satisfied: promise in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.2.0)\n",
      "Requirement already satisfied: importlib-resources in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.3.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from importlib-resources->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.21.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow_io->object-detection==0.1) (0.21.0)\n",
      "Building wheels for collected packages: object-detection\n",
      "  Building wheel for object-detection (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1679343 sha256=580efd356e143f4eb15d4dfcb8fef71c302b6ddaec0c69900d16c8a0a04837e2\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4ykcqtgd/wheels/a4/27/31/b41a2f9b118ebb35237b34adc3f408b0c60bd7f122d0a7eb79\n",
      "Successfully built object-detection\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "Installing collected packages: numpy, h5py, object-detection\n",
      "  Attempting uninstall: numpy\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "    Found existing installation: numpy 1.21.4\n",
      "    Uninstalling numpy-1.21.4:\n",
      "      Successfully uninstalled numpy-1.21.4\n",
      "  Attempting uninstall: h5py\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "    Found existing installation: h5py 2.9.0\n",
      "    Uninstalling h5py-2.9.0:\n",
      "      Successfully uninstalled h5py-2.9.0\n",
      "  Attempting uninstall: object-detection\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "    Found existing installation: object-detection 0.1\n",
      "    Uninstalling object-detection-0.1:\n",
      "      Successfully uninstalled object-detection-0.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fbprophet 0.7.1 requires cmdstanpy==0.9.5, which is not installed.\n",
      "fbprophet 0.7.1 requires setuptools-git>=1.2, which is not installed.\n",
      "tensorflow-gpu 2.5.0 requires grpcio~=1.34.0, but you have grpcio 1.41.1 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires tensorflow-estimator<2.6.0,>=2.5.0rc0, but you have tensorflow-estimator 2.2.0 which is incompatible.\n",
      "networkx 2.6.1 requires scipy!=1.6.1,>=1.5, but you have scipy 1.4.1 which is incompatible.\u001b[0m\n",
      "Successfully installed h5py-3.1.0 numpy-1.19.5 object-detection-0.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/anaconda/envs/py38_default/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%cd /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "%cp /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research/object_detection/packages/tf2/setup.py .\n",
    "!pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.3: Uninstall and install h5py\n",
    "\n",
    "Make sure to uninstall h5py and re-install it in the 2.9 version, because otherwise there might be problems with the training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "Found existing installation: h5py 3.1.0\n",
      "Uninstalling h5py-3.1.0:\n",
      "  Successfully uninstalled h5py-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall h5py -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "Collecting h5py==2.9\n",
      "  Using cached h5py-2.9.0-cp38-cp38-manylinux1_x86_64.whl (2.8 MB)\n",
      "Requirement already satisfied: six in /anaconda/envs/py38_default/lib/python3.8/site-packages (from h5py==2.9) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from h5py==2.9) (1.19.5)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "Installing collected packages: h5py\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.6.1 requires h5py~=3.1.0, but you have h5py 2.9.0 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires grpcio~=1.34.0, but you have grpcio 1.41.1 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires h5py~=3.1.0, but you have h5py 2.9.0 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires tensorflow-estimator<2.6.0,>=2.5.0rc0, but you have tensorflow-estimator 2.2.0 which is incompatible.\u001b[0m\n",
      "Successfully installed h5py-2.9.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/anaconda/envs/py38_default/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py==2.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Prepare the model for training\n",
    "\n",
    "Once everything is installed, import all the libraries that are needed and launch a sample training to check that everything works smoothly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wHfsJ5nWLWh9"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import io\n",
    "import imageio\n",
    "import glob\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, Javascript\n",
    "from IPython.display import Image as IPyImage\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from models.research.object_detection.utils import label_map_util\n",
    "from models.research.object_detection.utils import config_util\n",
    "from models.research.object_detection.utils import visualization_utils as viz_utils\n",
    "from models.research.object_detection.builders import model_builder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a pip freeze to see whether tensorflow-gpu is installed, and run the test to see everything works smoothly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wh_HPMOqWH9z",
    "outputId": "31063c4e-d8f1-484e-c325-005553c763eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests under Python 3.8.10: /anaconda/envs/py38_default/bin/python\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2021-11-28 22:06:05.825570: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-28 22:06:06.434133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10801 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0001:00:00.0, compute capability: 3.7\n",
      "/anaconda/envs/py38_default/lib/python3.8/site-packages/object_detection/builders/model_builder.py:1100: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W1128 22:06:06.816695 140684057838528 model_builder.py:1100] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.27s\n",
      "I1128 22:06:07.094763 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.27s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.65s\n",
      "I1128 22:06:07.745564 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.65s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.28s\n",
      "I1128 22:06:08.025614 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.28s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.26s\n",
      "I1128 22:06:08.282119 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.26s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.9s\n",
      "I1128 22:06:10.177772 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.9s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I1128 22:06:10.179060 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "I1128 22:06:10.202730 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "I1128 22:06:10.217828 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "I1128 22:06:10.233635 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.1s\n",
      "I1128 22:06:10.333349 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.1s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
      "I1128 22:06:10.427059 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n",
      "I1128 22:06:10.526757 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n",
      "I1128 22:06:10.623882 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
      "I1128 22:06:10.717989 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
      "I1128 22:06:10.745169 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I1128 22:06:10.918409 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I1128 22:06:10.918563 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
      "I1128 22:06:10.918655 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 3\n",
      "I1128 22:06:10.920819 140684057838528 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I1128 22:06:10.937654 140684057838528 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I1128 22:06:10.937756 140684057838528 efficientnet_model.py:147] round_filter input=16 output=16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1128 22:06:10.996378 140684057838528 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I1128 22:06:10.996489 140684057838528 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I1128 22:06:11.149071 140684057838528 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I1128 22:06:11.149238 140684057838528 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I1128 22:06:11.305337 140684057838528 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I1128 22:06:11.305535 140684057838528 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I1128 22:06:11.730204 140684057838528 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I1128 22:06:11.730388 140684057838528 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I1128 22:06:11.958428 140684057838528 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I1128 22:06:11.958610 140684057838528 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I1128 22:06:12.268843 140684057838528 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I1128 22:06:12.269027 140684057838528 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I1128 22:06:12.342005 140684057838528 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I1128 22:06:12.371041 140684057838528 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1128 22:06:12.423778 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I1128 22:06:12.423929 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
      "I1128 22:06:12.424001 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 4\n",
      "I1128 22:06:12.425655 140684057838528 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I1128 22:06:12.441004 140684057838528 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I1128 22:06:12.441114 140684057838528 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I1128 22:06:12.562011 140684057838528 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I1128 22:06:12.562156 140684057838528 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I1128 22:06:12.789191 140684057838528 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I1128 22:06:12.789375 140684057838528 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I1128 22:06:13.016867 140684057838528 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I1128 22:06:13.017050 140684057838528 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I1128 22:06:13.348524 140684057838528 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I1128 22:06:13.348739 140684057838528 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I1128 22:06:13.654944 140684057838528 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I1128 22:06:13.655152 140684057838528 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I1128 22:06:14.035421 140684057838528 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I1128 22:06:14.035619 140684057838528 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I1128 22:06:14.185333 140684057838528 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I1128 22:06:14.213522 140684057838528 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1128 22:06:14.274278 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I1128 22:06:14.274418 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
      "I1128 22:06:14.274492 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 5\n",
      "I1128 22:06:14.276071 140684057838528 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I1128 22:06:14.291335 140684057838528 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I1128 22:06:14.291431 140684057838528 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I1128 22:06:14.410873 140684057838528 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I1128 22:06:14.411033 140684057838528 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I1128 22:06:14.637809 140684057838528 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I1128 22:06:14.637966 140684057838528 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I1128 22:06:14.864926 140684057838528 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I1128 22:06:14.865113 140684057838528 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I1128 22:06:15.171418 140684057838528 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I1128 22:06:15.171618 140684057838528 efficientnet_model.py:147] round_filter input=112 output=120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1128 22:06:15.720984 140684057838528 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I1128 22:06:15.721185 140684057838528 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I1128 22:06:16.117013 140684057838528 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I1128 22:06:16.117206 140684057838528 efficientnet_model.py:147] round_filter input=320 output=352\n",
      "I1128 22:06:16.271535 140684057838528 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
      "I1128 22:06:16.303682 140684057838528 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1128 22:06:16.364893 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I1128 22:06:16.365071 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
      "I1128 22:06:16.365158 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 6\n",
      "I1128 22:06:16.367545 140684057838528 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I1128 22:06:16.383827 140684057838528 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I1128 22:06:16.383936 140684057838528 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I1128 22:06:16.508438 140684057838528 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I1128 22:06:16.508630 140684057838528 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I1128 22:06:16.752727 140684057838528 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I1128 22:06:16.752916 140684057838528 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I1128 22:06:16.986303 140684057838528 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I1128 22:06:16.986484 140684057838528 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I1128 22:06:17.379266 140684057838528 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I1128 22:06:17.379451 140684057838528 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I1128 22:06:17.773779 140684057838528 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I1128 22:06:17.773962 140684057838528 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I1128 22:06:18.234527 140684057838528 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I1128 22:06:18.234728 140684057838528 efficientnet_model.py:147] round_filter input=320 output=384\n",
      "I1128 22:06:18.386764 140684057838528 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
      "I1128 22:06:18.415370 140684057838528 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1128 22:06:18.482552 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I1128 22:06:18.482747 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
      "I1128 22:06:18.482821 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 7\n",
      "I1128 22:06:18.484458 140684057838528 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I1128 22:06:18.500451 140684057838528 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I1128 22:06:18.500551 140684057838528 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I1128 22:06:18.623077 140684057838528 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I1128 22:06:18.623278 140684057838528 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I1128 22:06:18.935310 140684057838528 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I1128 22:06:18.935503 140684057838528 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I1128 22:06:19.250318 140684057838528 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I1128 22:06:19.250503 140684057838528 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I1128 22:06:20.019475 140684057838528 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I1128 22:06:20.019683 140684057838528 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I1128 22:06:20.500266 140684057838528 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I1128 22:06:20.500478 140684057838528 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I1128 22:06:21.160059 140684057838528 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I1128 22:06:21.160276 140684057838528 efficientnet_model.py:147] round_filter input=320 output=448\n",
      "I1128 22:06:21.316253 140684057838528 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
      "I1128 22:06:21.345010 140684057838528 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1128 22:06:21.424347 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I1128 22:06:21.424498 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
      "I1128 22:06:21.424571 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 7\n",
      "I1128 22:06:21.426242 140684057838528 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I1128 22:06:21.443212 140684057838528 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I1128 22:06:21.443313 140684057838528 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I1128 22:06:21.631481 140684057838528 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I1128 22:06:21.631667 140684057838528 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I1128 22:06:22.027720 140684057838528 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I1128 22:06:22.027911 140684057838528 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I1128 22:06:22.422690 140684057838528 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I1128 22:06:22.422878 140684057838528 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I1128 22:06:22.971224 140684057838528 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I1128 22:06:22.971409 140684057838528 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I1128 22:06:23.508324 140684057838528 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I1128 22:06:23.508506 140684057838528 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I1128 22:06:24.223574 140684057838528 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I1128 22:06:24.223784 140684057838528 efficientnet_model.py:147] round_filter input=320 output=512\n",
      "I1128 22:06:24.454490 140684057838528 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
      "I1128 22:06:24.482560 140684057838528 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1128 22:06:24.857342 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I1128 22:06:24.857542 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I1128 22:06:24.857634 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 8\n",
      "I1128 22:06:24.859299 140684057838528 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I1128 22:06:24.875432 140684057838528 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I1128 22:06:24.875530 140684057838528 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I1128 22:06:25.061000 140684057838528 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I1128 22:06:25.061220 140684057838528 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I1128 22:06:25.525949 140684057838528 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I1128 22:06:25.526188 140684057838528 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I1128 22:06:26.003012 140684057838528 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I1128 22:06:26.003218 140684057838528 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I1128 22:06:26.644468 140684057838528 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I1128 22:06:26.644723 140684057838528 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I1128 22:06:27.374635 140684057838528 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I1128 22:06:27.374823 140684057838528 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I1128 22:06:28.234735 140684057838528 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I1128 22:06:28.234948 140684057838528 efficientnet_model.py:147] round_filter input=320 output=576\n",
      "I1128 22:06:28.476318 140684057838528 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
      "I1128 22:06:28.506671 140684057838528 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1128 22:06:28.604770 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I1128 22:06:28.604933 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I1128 22:06:28.605005 140684057838528 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 8\n",
      "I1128 22:06:28.606667 140684057838528 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I1128 22:06:28.622396 140684057838528 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I1128 22:06:28.622495 140684057838528 efficientnet_model.py:147] round_filter input=16 output=32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1128 22:06:28.867114 140684057838528 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I1128 22:06:28.867296 140684057838528 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I1128 22:06:29.406507 140684057838528 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I1128 22:06:29.406694 140684057838528 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I1128 22:06:30.312699 140684057838528 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I1128 22:06:30.312884 140684057838528 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I1128 22:06:31.094045 140684057838528 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I1128 22:06:31.094250 140684057838528 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I1128 22:06:31.888327 140684057838528 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I1128 22:06:31.888518 140684057838528 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I1128 22:06:32.919678 140684057838528 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I1128 22:06:32.919869 140684057838528 efficientnet_model.py:147] round_filter input=320 output=640\n",
      "I1128 22:06:33.234210 140684057838528 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
      "I1128 22:06:33.263958 140684057838528 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.64s\n",
      "I1128 22:06:33.383629 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.64s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I1128 22:06:33.395998 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I1128 22:06:33.397677 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I1128 22:06:33.398131 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I1128 22:06:33.399661 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I1128 22:06:33.401465 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I1128 22:06:33.401891 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I1128 22:06:33.402920 140684057838528 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 27.583s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "#run model builder test\n",
    "!python /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research/object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1: Import the data\n",
    "\n",
    "Change current directory to be sure everything works smoothly. This process of directory change will take place often to ensure code compatibility when constructing paths. \n",
    "\n",
    "Eventually, also remember to change the names of the files so that they are compatible with yours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training\n"
     ]
    }
   ],
   "source": [
    "%cd /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/pictures/output_tfrecords_v2/train/merged_logos.tfrecord\n",
      "/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/pictures/output_tfrecords_v2/train/logos_label_map.pbtxt\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Set the pictures directory to be the one containing your train and validation folders of interest\n",
    "picture_files_directory = \"/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/pictures/\"\n",
    "\n",
    "# Set the names of the folders to respect the right path to the TFRecords\n",
    "test_record_fname = os.path.join(picture_files_directory,\"output_tfrecords_v2/valid/merged_logos.tfrecord\")\n",
    "train_record_fname = os.path.join(picture_files_directory,\"output_tfrecords_v2/train/merged_logos.tfrecord\")\n",
    "label_map_pbtxt_fname = os.path.join(picture_files_directory, \"output_tfrecords_v2/train/logos_label_map.pbtxt\")\n",
    "\n",
    "print(train_record_fname,label_map_pbtxt_fname, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2MAcgJ53STW"
   },
   "source": [
    "## Step 2.2: Configure Custom TensorFlow2 Object Detection Training Configuration\n",
    "\n",
    "To be able to use different models, we populated the file ModelSetting.py with the models we thought would be good to train. \n",
    "\n",
    "From the ModelZoo, it is possible to pick the pre_trained_checkpoints (extension tar.gz) and the model_name (that must be the same as the one given to the pre_trained_checkpoints):\n",
    "https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
    "\n",
    "By entering the *raw* version of the ModelZoo page on GitHub, it is possible to pick the the names of the tar.gz.\n",
    "\n",
    "To find instead the configurations: \n",
    "https://github.com/tensorflow/models/tree/master/research/object_detection/configs/tf2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training\n"
     ]
    }
   ],
   "source": [
    "%cd /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "Requirement already satisfied: prettyprinter in /anaconda/envs/py38_default/lib/python3.8/site-packages (0.18.0)\n",
      "Requirement already satisfied: colorful>=0.4.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from prettyprinter) (0.5.4)\n",
      "Requirement already satisfied: Pygments>=2.2.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from prettyprinter) (2.9.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/anaconda/envs/py38_default/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install prettyprinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training\n"
     ]
    }
   ],
   "source": [
    "%cd /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gN0EUEa3e5Un"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    'efficientdet-d0': {\n",
      "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
      "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
      "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
      "        'batch_size': 16\n",
      "    },\n",
      "    'faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8': {\n",
      "        'model_name': 'faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8',\n",
      "        'base_pipeline_file': 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config',\n",
      "        'pretrained_checkpoint': 'faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8.tar.gz',\n",
      "        'batch_size': 2\n",
      "    },\n",
      "    'ssd_resnet152_v1': {\n",
      "        'model_name': 'ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8',\n",
      "        'base_pipeline_file': 'ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8.config',\n",
      "        'pretrained_checkpoint': 'ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8.tar.gz',\n",
      "        'batch_size': 2\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Step 1: import model settings\n",
    "# For each model, this file returns important info to actually use the model\n",
    "\n",
    "from ModelSettings import Model_Setting\n",
    "from prettyprinter import pprint\n",
    "\n",
    "MODELS_CONFIG = Model_Setting()\n",
    "\n",
    "pprint(MODELS_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: chose the model and extract relevant info\n",
    "\n",
    "chosen_model = 'efficientdet-d0'\n",
    "\n",
    "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
    "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
    "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
    "batch_size = MODELS_CONFIG[chosen_model]['batch_size'] #if you can fit a large batch in memory, it may speed up your training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The more steps, the longer the training. \n",
    "# Increase if your loss function is still decreasing and validation metrics are increasing. \n",
    "num_steps = 500000\n",
    "\n",
    "#Perform evaluation after so many steps\n",
    "num_eval_steps = 3000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXTRA: Deploy folder structure\n",
    "\n",
    "Inside the \"research\" folder, we will create a \"deploy\" folder in which we will dump all the data related to the model used and its specific configuration. <br>\n",
    "For this reason, the structure of the deploy folder is as follows:\n",
    "\n",
    "Deploy:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Model A:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Config 1<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Config 2<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;...<br>\n",
    "\n",
    "This means that, once we choose a model:\n",
    "1. if there is no folder within \"deploy\" with the model name, then create it and create the the Config 1 folder within the model folder.\n",
    "2. if there is a folder with the name of the model, we need to check if the configurtion of the current model is the same as the one in the folder. If not, create a new Config folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research\n"
     ]
    }
   ],
   "source": [
    "%cd /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If it does not exist already, create the 'deploy' folder inside training/models/research\n",
    "\n",
    "main_deploy_folder = '/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research/deploy'\n",
    "\n",
    "if \"deploy\" not in os.listdir(os.getcwd()):\n",
    "    os.mkdir(main_deploy_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_configs_for_model(chosen_model):\n",
    "    \n",
    "    # This is a dict with config folder names as keys and values of the config as values\n",
    "    folder_to_values = dict()\n",
    "    \n",
    "    model_path = os.path.join(main_deploy_folder, chosen_model)\n",
    "    \n",
    "    for config_folder in os.listdir(model_path):\n",
    "        if not config_folder == \".ipynb_checkpoints\":\n",
    "            print(config_folder)\n",
    "            config_path = os.path.join(model_path, config_folder)\n",
    "\n",
    "            config_file = os.path.join(config_path,r'pipeline_file.config')\n",
    "            config_values = list()\n",
    "\n",
    "            with open(config_file) as f:\n",
    "                file = f.read()\n",
    "\n",
    "                # Extract all values except the path of the data\n",
    "                # This mean that if we train the same config of a model on a different version of the data, this will overwrite the results\n",
    "                # TODO: add path of the data as well?\n",
    "                # TODO: add fine tune check points?\n",
    "                config_values.append(re.search('batch_size: [0-9]+', file).group()[len('batch_size: '):])\n",
    "                config_values.append(re.search('num_steps: [0-9]+', file).group()[len('num_steps: '):])\n",
    "                config_values.append(re.search('num_classes: [0-9]+', file).group()[len('num_classes: '):])\n",
    "\n",
    "            folder_to_values[config_folder] = config_values\n",
    "        \n",
    "    return folder_to_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "b_ki9jOqxn7V"
   },
   "outputs": [],
   "source": [
    "def get_num_classes(pbtxt_fname):\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['16', '500000', '12']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_config = [\n",
    "    str(batch_size),\n",
    "    str(num_steps),\n",
    "    str(num_classes)\n",
    "]\n",
    "\n",
    "current_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'efficientdet-d0'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the model has never been used, then create folder for the model and for the current config, the latter inside the former\n",
    "\n",
    "def update_repo_structure(chosen_model):\n",
    "    \n",
    "    model_folder = main_deploy_folder + '/' + chosen_model\n",
    "    \n",
    "    # TODO: it has to be folder, not file\n",
    "    if chosen_model not in os.listdir(main_deploy_folder):\n",
    "        # Case 1: model never used\n",
    "        os.mkdir(model_folder)\n",
    "\n",
    "        config_folder = model_folder + '/config_1'\n",
    "        os.mkdir(config_folder)\n",
    "\n",
    "        print('case1')\n",
    "        print(config_folder)\n",
    "\n",
    "    else:\n",
    "        # Case 2: model already used\n",
    "\n",
    "        list_configs = extract_configs_for_model(chosen_model)\n",
    "        print(list_configs)\n",
    "\n",
    "        if current_config in list(list_configs.values()):\n",
    "            \n",
    "            # Case A: Specifics configs per model already used\n",
    "            for key in list(list_configs.keys()):\n",
    "                if list_configs[key] == current_config:\n",
    "                    config_folder = key\n",
    "                    print('case a')\n",
    "                    print(config_folder)\n",
    "\n",
    "        else:\n",
    "            # Case B: new configs\n",
    "            config_folder = model_folder + f'/config_{len(list_configs)+1}'\n",
    "            os.mkdir(config_folder)\n",
    "            print('case b')\n",
    "            print(config_folder)\n",
    "            \n",
    "    return config_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config_1\n",
      "config_6\n",
      "config_3\n",
      "config_7\n",
      "config_4\n",
      "config_2\n",
      "config_5\n",
      "{'config_1': ['15', '40010', '9'], 'config_6': ['16', '400000', '9'], 'config_3': ['15', '40010', '9'], 'config_7': ['16', '500000', '12'], 'config_4': ['16', '40080', '9'], 'config_2': ['13', '40020', '9'], 'config_5': ['16', '40100', '9']}\n",
      "case a\n",
      "config_7\n"
     ]
    }
   ],
   "source": [
    "# Obtain the proper config folder to use in the next cells \n",
    "\n",
    "config_subfolder = update_repo_structure(chosen_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research/deploy/efficientdet-d0/config_7'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_folder = os.path.join(os.path.join(main_deploy_folder, chosen_model),config_subfolder)\n",
    "config_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kG4TmJUVrYQ7",
    "outputId": "a7a90aca-9383-4007-b6fb-02729ee02e37"
   },
   "outputs": [],
   "source": [
    "# Step 3.a: using info from step 2, download the weights of the model\n",
    "\n",
    "import tarfile\n",
    "import requests\n",
    "\n",
    "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
    "\n",
    "file_to_be_opened = os.path.join(config_folder, pretrained_checkpoint)\n",
    "\n",
    "# Unzip the tar.gz\n",
    "response = requests.get(download_tar, stream=True)\n",
    "if response.status_code == 200:\n",
    "    with open(file_to_be_opened, 'wb') as f:\n",
    "        f.write(response.raw.read())\n",
    "\n",
    "tar = tarfile.open(file_to_be_opened)\n",
    "tar.extractall(path=config_folder)\n",
    "tar.close()\n",
    "\n",
    "# TODO: once the tar has been extracted, delete the tar file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-nqYZtdtsgG",
    "outputId": "48f68a17-6ec5-4436-8ff0-a4d549186709"
   },
   "outputs": [],
   "source": [
    "# Step 3.b: using info from step 2, download base training configuration file\n",
    "\n",
    "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
    "\n",
    "abrir = os.path.join(config_folder, base_pipeline_file)\n",
    "\n",
    "response = requests.get(download_config, stream=True)\n",
    "if response.status_code == 200:\n",
    "    with open(abrir, 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research/deploy/efficientdet-d0/config_7/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n",
      "/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research/deploy/efficientdet-d0/config_7/efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0\n"
     ]
    }
   ],
   "source": [
    "pipeline_fname = os.path.join(config_folder, base_pipeline_file)\n",
    "print(pipeline_fname)\n",
    "\n",
    "fine_tune_checkpoint = os.path.join(config_folder, model_name,\"checkpoint\", \"ckpt-0\")\n",
    "print(fine_tune_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5eA5ht3_yukT",
    "outputId": "fe9716f3-ed98-4a17-f80c-83660b05bdfe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Written fine tune checkpoint\n",
      "INFO:root:Written input path\n",
      "INFO:root:Written label map\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing custom configuration file\n"
     ]
    }
   ],
   "source": [
    "# Write custom configuration file by slotting our dataset, model checkpoint, and training parameters into \n",
    "# the base pipeline file\n",
    "\n",
    "import re\n",
    "\n",
    "print('writing custom configuration file')\n",
    "\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()\n",
    "\n",
    "with open(os.path.join(config_folder, r'pipeline_file.config'), 'w') as f:\n",
    "    \n",
    "    # fine_tune_checkpoint\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               f'fine_tune_checkpoint: \"{fine_tune_checkpoint}\"', s)\n",
    "    \n",
    "    logging.info(\"Written fine tune checkpoint\")\n",
    "    \n",
    "    # tfrecord files train and test.\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', f'input_path: \"{train_record_fname}\"', s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', f'input_path: \"{test_record_fname}\"', s)\n",
    "    \n",
    "    logging.info(\"Written input path\")\n",
    "\n",
    "    # label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', f'label_map_path: \"{label_map_pbtxt_fname}\"', s)\n",
    "    \n",
    "    logging.info(\"Written label map\")\n",
    "\n",
    "    # Set training batch_size.\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               f'batch_size: {batch_size}', s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               f'num_steps: {num_steps}', s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               f'num_classes: {num_classes}', s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('learning_rate_base: [a-z.0-9-]+',\n",
    "               f'learning_rate_base: 0.08', s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('warmup_learning_rate: [a-z.0-9-]+',\n",
    "               f'warmup_learning_rate: 0.001', s)\n",
    "    \n",
    "    #fine-tune checkpoint type\n",
    "    s = re.sub(\n",
    "        'fine_tune_checkpoint_type: \"classification\"', \n",
    "        'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
    "    \n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training\n"
     ]
    }
   ],
   "source": [
    "%cd /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research/deploy/efficientdet-d0/config_7/pipeline_file.config'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_file = os.path.join(config_folder, 'pipeline_file.config')\n",
    "pipeline_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "GMlaN3rs3zLe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:The directory TENSOR_RESULTS is already present, files will be stored there\n"
     ]
    }
   ],
   "source": [
    "# Create the TENSOR_RESULTS directory, to store our models\n",
    "\n",
    "if \"TENSOR_RESULTS\" not in os.listdir(os.getcwd()):\n",
    "    os.mkdir(os.path.join(os.getcwd(),\"TENSOR_RESULTS\"))\n",
    "    logging.info(\"Creating the directory TENSOR_RESULTS because it did not exist\") \n",
    "else:\n",
    "    logging.info(\"The directory TENSOR_RESULTS is already present, files will be stored there\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:The folder model_run_directory WAS ALREADY PRESENT and is set to be: \n",
      " /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/TENSOR_RESULTS/efficientdet-d0\n",
      "INFO:root:The folder model_dir WAS ALREADY PRESENT and is set to be: \n",
      " /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/TENSOR_RESULTS/efficientdet-d0/config_7\n"
     ]
    }
   ],
   "source": [
    "tensor_results_directory = '/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/TENSOR_RESULTS'\n",
    "\n",
    "model_run_directory = os.path.join('/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/TENSOR_RESULTS',\n",
    "                                  chosen_model)\n",
    "\n",
    "# Similarly to what we did for the configurations, we generate model results subdirectories inside TENSOR_RESULTS to then\n",
    "# be able to restore the already-trained checkpoints\n",
    "\n",
    "if chosen_model not in os.listdir(tensor_results_directory):\n",
    "    try:\n",
    "        os.mkdir(os.path.join(tensor_results_directory, chosen_model))\n",
    "        logging.info(f\"The folder model_run_directory is set to be: \\n {model_run_directory}\")\n",
    "    except FileExistsError:\n",
    "        logging.info(f\"FILEEXISTSERROR: The folder model_run_directory is set to be: \\n {model_run_directory}\")\n",
    "else:\n",
    "    logging.info(f\"The folder model_run_directory WAS ALREADY PRESENT and is set to be: \\n {model_run_directory}\")\n",
    "\n",
    "model_dir = os.path.join(model_run_directory, config_subfolder.split(\"/\")[-1])\n",
    "\n",
    "if config_subfolder.split(\"/\")[-1] not in os.listdir(model_run_directory):\n",
    "    try:\n",
    "        os.mkdir(os.path.join(model_run_directory, config_subfolder))\n",
    "        logging.info(f\"The folder model_dir is set to be: \\n {model_dir}\")\n",
    "    except FileExistsError:\n",
    "        logging.info(f\"FILEEXISTSERROR: The folder model_dir WAS ALREADY PRESENT and is set to be: \\n {model_dir}\")\n",
    "else:\n",
    "    logging.info(f\"The folder model_dir WAS ALREADY PRESENT and is set to be: \\n {model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxPj_QV43qD5"
   },
   "source": [
    "# Step 3: Train Custom TF2 Object Detector\n",
    "\n",
    "With this information, we can start training the model:\n",
    "\n",
    "* pipeline_file: defined above in writing custom training configuration\n",
    "* model_dir: the location tensorboard logs and saved model checkpoints will save to\n",
    "* num_train_steps: how long to train for\n",
    "* num_eval_steps: perform eval on validation set after this many steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE FILE: /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research/deploy/efficientdet-d0/config_7/pipeline_file.config\n",
      "\n",
      "MODEL DIRECTORY: /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/TENSOR_RESULTS/efficientdet-d0/config_7\n",
      "\n",
      "NUMBER OF STEPS: 500000\n",
      "\n",
      "NUMBER OF EVALUATION STEPS: 3000\n"
     ]
    }
   ],
   "source": [
    "print(\"PIPELINE FILE: \" + str(pipeline_file), \n",
    "      \"MODEL DIRECTORY: \" + str(model_dir), \n",
    "      \"NUMBER OF STEPS: \" + str(num_steps), \n",
    "      \"NUMBER OF EVALUATION STEPS: \" + str(num_eval_steps), \n",
    "      sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "Requirement already satisfied: numpy in /anaconda/envs/py38_default/lib/python3.8/site-packages (1.19.5)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.21.4-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fbprophet 0.7.1 requires cmdstanpy==0.9.5, which is not installed.\n",
      "fbprophet 0.7.1 requires setuptools-git>=1.2, which is not installed.\n",
      "tensorflow 2.6.1 requires h5py~=3.1.0, but you have h5py 2.9.0 which is incompatible.\n",
      "tensorflow 2.6.1 requires numpy~=1.19.2, but you have numpy 1.21.4 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires grpcio~=1.34.0, but you have grpcio 1.41.1 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires h5py~=3.1.0, but you have h5py 2.9.0 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires numpy~=1.19.2, but you have numpy 1.21.4 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires tensorflow-estimator<2.6.0,>=2.5.0rc0, but you have tensorflow-estimator 2.2.0 which is incompatible.\n",
      "networkx 2.6.1 requires scipy!=1.6.1,>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
      "apache-beam 2.33.0 requires numpy<1.21.0,>=1.14.3, but you have numpy 1.21.4 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.21.4\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/anaconda/envs/py38_default/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU presence and regularize their usage\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.1: Fire the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQTfZChVzzpZ",
    "outputId": "48bf9506-ddd1-4de9-9629-d55602e1fea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-28 22:06:49.266090: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-28 22:06:49.850113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10801 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0001:00:00.0, compute capability: 3.7\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I1128 22:06:49.983823 140606687830976 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 500000\n",
      "I1128 22:06:49.988577 140606687830976 config_util.py:552] Maybe overwriting train_steps: 500000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I1128 22:06:49.988694 140606687830976 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "I1128 22:06:49.998177 140606687830976 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I1128 22:06:49.998277 140606687830976 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
      "I1128 22:06:49.998347 140606687830976 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 3\n",
      "I1128 22:06:50.003221 140606687830976 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1128 22:06:50.022513 140606687830976 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1128 22:06:50.024138 140606687830976 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1128 22:06:50.026327 140606687830976 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1128 22:06:50.027195 140606687830976 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1128 22:06:50.034168 140606687830976 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1128 22:06:50.037538 140606687830976 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1128 22:06:50.043197 140606687830976 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I1128 22:06:50.043295 140606687830976 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1128 22:06:50.057096 140606687830976 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1128 22:06:50.057981 140606687830976 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1128 22:06:50.059676 140606687830976 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1128 22:06:50.060513 140606687830976 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1128 22:06:50.139882 140606687830976 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I1128 22:06:50.140005 140606687830976 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I1128 22:06:50.554965 140606687830976 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I1128 22:06:50.555163 140606687830976 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I1128 22:06:50.807934 140606687830976 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I1128 22:06:50.808104 140606687830976 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I1128 22:06:51.198748 140606687830976 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I1128 22:06:51.198933 140606687830976 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I1128 22:06:51.581328 140606687830976 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I1128 22:06:51.581533 140606687830976 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I1128 22:06:52.092890 140606687830976 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I1128 22:06:52.093090 140606687830976 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I1128 22:06:52.216492 140606687830976 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I1128 22:06:52.264798 140606687830976 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/py38_default/lib/python3.8/site-packages/object_detection/model_lib_v2.py:557: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W1128 22:06:52.308009 140606687830976 deprecation.py:339] From /anaconda/envs/py38_default/lib/python3.8/site-packages/object_detection/model_lib_v2.py:557: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/pictures/output_tfrecords_v2/train/merged_logos.tfrecord']\n",
      "I1128 22:06:52.315169 140606687830976 dataset_builder.py:163] Reading unweighted datasets: ['/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/pictures/output_tfrecords_v2/train/merged_logos.tfrecord']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/pictures/output_tfrecords_v2/train/merged_logos.tfrecord']\n",
      "I1128 22:06:52.315358 140606687830976 dataset_builder.py:80] Reading record datasets for input file: ['/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/pictures/output_tfrecords_v2/train/merged_logos.tfrecord']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I1128 22:06:52.315448 140606687830976 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W1128 22:06:52.315517 140606687830976 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /anaconda/envs/py38_default/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W1128 22:06:52.317532 140606687830976 deprecation.py:339] From /anaconda/envs/py38_default/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /anaconda/envs/py38_default/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W1128 22:06:52.340524 140606687830976 deprecation.py:339] From /anaconda/envs/py38_default/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /anaconda/envs/py38_default/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W1128 22:06:59.851782 140606687830976 deprecation.py:339] From /anaconda/envs/py38_default/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /anaconda/envs/py38_default/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1128 22:07:03.844872 140606687830976 deprecation.py:339] From /anaconda/envs/py38_default/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2021-11-28 22:07:06.300186: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "/anaconda/envs/py38_default/lib/python3.8/site-packages/keras/backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "2021-11-28 22:07:42.143029: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8202\n",
      "WARNING:tensorflow:From /anaconda/envs/py38_default/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W1128 22:07:50.396260 140600760063744 deprecation.py:542] From /anaconda/envs/py38_default/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "W1128 22:08:01.097342 140600760063744 utils.py:75] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "W1128 22:08:15.681558 140600760063744 utils.py:75] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "W1128 22:08:29.639513 140600760063744 utils.py:75] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "W1128 22:08:44.329161 140600760063744 utils.py:75] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "INFO:tensorflow:Step 153100 per-step time 3.814s\n",
      "I1128 22:14:11.156254 140606687830976 model_lib_v2.py:698] Step 153100 per-step time 3.814s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.4164543,\n",
      " 'Loss/localization_loss': 0.16577749,\n",
      " 'Loss/regularization_loss': 0.073743835,\n",
      " 'Loss/total_loss': 0.65597564,\n",
      " 'learning_rate': 0.039218605}\n",
      "I1128 22:14:11.156593 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.4164543,\n",
      " 'Loss/localization_loss': 0.16577749,\n",
      " 'Loss/regularization_loss': 0.073743835,\n",
      " 'Loss/total_loss': 0.65597564,\n",
      " 'learning_rate': 0.039218605}\n",
      "INFO:tensorflow:Step 153200 per-step time 2.772s\n",
      "I1128 22:18:48.376577 140606687830976 model_lib_v2.py:698] Step 153200 per-step time 2.772s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.33412975,\n",
      " 'Loss/localization_loss': 0.22672616,\n",
      " 'Loss/regularization_loss': 0.07373695,\n",
      " 'Loss/total_loss': 0.6345929,\n",
      " 'learning_rate': 0.03917638}\n",
      "I1128 22:18:48.376912 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.33412975,\n",
      " 'Loss/localization_loss': 0.22672616,\n",
      " 'Loss/regularization_loss': 0.07373695,\n",
      " 'Loss/total_loss': 0.6345929,\n",
      " 'learning_rate': 0.03917638}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 153300 per-step time 2.767s\n",
      "I1128 22:23:25.067133 140606687830976 model_lib_v2.py:698] Step 153300 per-step time 2.767s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.27493238,\n",
      " 'Loss/localization_loss': 0.15783383,\n",
      " 'Loss/regularization_loss': 0.073738046,\n",
      " 'Loss/total_loss': 0.50650424,\n",
      " 'learning_rate': 0.03913415}\n",
      "I1128 22:23:25.067452 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.27493238,\n",
      " 'Loss/localization_loss': 0.15783383,\n",
      " 'Loss/regularization_loss': 0.073738046,\n",
      " 'Loss/total_loss': 0.50650424,\n",
      " 'learning_rate': 0.03913415}\n",
      "INFO:tensorflow:Step 153400 per-step time 2.778s\n",
      "I1128 22:28:02.823930 140606687830976 model_lib_v2.py:698] Step 153400 per-step time 2.778s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.23322596,\n",
      " 'Loss/localization_loss': 0.20176123,\n",
      " 'Loss/regularization_loss': 0.073731564,\n",
      " 'Loss/total_loss': 0.5087187,\n",
      " 'learning_rate': 0.03909192}\n",
      "I1128 22:28:02.824252 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.23322596,\n",
      " 'Loss/localization_loss': 0.20176123,\n",
      " 'Loss/regularization_loss': 0.073731564,\n",
      " 'Loss/total_loss': 0.5087187,\n",
      " 'learning_rate': 0.03909192}\n",
      "INFO:tensorflow:Step 153500 per-step time 2.773s\n",
      "I1128 22:32:40.139533 140606687830976 model_lib_v2.py:698] Step 153500 per-step time 2.773s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.25519451,\n",
      " 'Loss/localization_loss': 0.15865295,\n",
      " 'Loss/regularization_loss': 0.07372329,\n",
      " 'Loss/total_loss': 0.48757076,\n",
      " 'learning_rate': 0.03904969}\n",
      "I1128 22:32:40.139853 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.25519451,\n",
      " 'Loss/localization_loss': 0.15865295,\n",
      " 'Loss/regularization_loss': 0.07372329,\n",
      " 'Loss/total_loss': 0.48757076,\n",
      " 'learning_rate': 0.03904969}\n",
      "INFO:tensorflow:Step 153600 per-step time 2.780s\n",
      "I1128 22:37:18.101596 140606687830976 model_lib_v2.py:698] Step 153600 per-step time 2.780s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.24075553,\n",
      " 'Loss/localization_loss': 0.14638563,\n",
      " 'Loss/regularization_loss': 0.07371563,\n",
      " 'Loss/total_loss': 0.4608568,\n",
      " 'learning_rate': 0.039007463}\n",
      "I1128 22:37:18.101957 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.24075553,\n",
      " 'Loss/localization_loss': 0.14638563,\n",
      " 'Loss/regularization_loss': 0.07371563,\n",
      " 'Loss/total_loss': 0.4608568,\n",
      " 'learning_rate': 0.039007463}\n",
      "INFO:tensorflow:Step 153700 per-step time 2.770s\n",
      "I1128 22:41:55.131874 140606687830976 model_lib_v2.py:698] Step 153700 per-step time 2.770s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.21223415,\n",
      " 'Loss/localization_loss': 0.16647062,\n",
      " 'Loss/regularization_loss': 0.07369919,\n",
      " 'Loss/total_loss': 0.45240396,\n",
      " 'learning_rate': 0.03896524}\n",
      "I1128 22:41:55.132229 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.21223415,\n",
      " 'Loss/localization_loss': 0.16647062,\n",
      " 'Loss/regularization_loss': 0.07369919,\n",
      " 'Loss/total_loss': 0.45240396,\n",
      " 'learning_rate': 0.03896524}\n",
      "INFO:tensorflow:Step 153800 per-step time 2.780s\n",
      "I1128 22:46:33.138513 140606687830976 model_lib_v2.py:698] Step 153800 per-step time 2.780s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3564099,\n",
      " 'Loss/localization_loss': 0.15927038,\n",
      " 'Loss/regularization_loss': 0.073689915,\n",
      " 'Loss/total_loss': 0.5893702,\n",
      " 'learning_rate': 0.03892301}\n",
      "I1128 22:46:33.138847 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.3564099,\n",
      " 'Loss/localization_loss': 0.15927038,\n",
      " 'Loss/regularization_loss': 0.073689915,\n",
      " 'Loss/total_loss': 0.5893702,\n",
      " 'learning_rate': 0.03892301}\n",
      "INFO:tensorflow:Step 153900 per-step time 2.774s\n",
      "I1128 22:51:10.507652 140606687830976 model_lib_v2.py:698] Step 153900 per-step time 2.774s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.27714303,\n",
      " 'Loss/localization_loss': 0.18870172,\n",
      " 'Loss/regularization_loss': 0.07367475,\n",
      " 'Loss/total_loss': 0.53951955,\n",
      " 'learning_rate': 0.038880784}\n",
      "I1128 22:51:10.507957 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.27714303,\n",
      " 'Loss/localization_loss': 0.18870172,\n",
      " 'Loss/regularization_loss': 0.07367475,\n",
      " 'Loss/total_loss': 0.53951955,\n",
      " 'learning_rate': 0.038880784}\n",
      "INFO:tensorflow:Step 154000 per-step time 2.768s\n",
      "I1128 22:55:47.348466 140606687830976 model_lib_v2.py:698] Step 154000 per-step time 2.768s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2683021,\n",
      " 'Loss/localization_loss': 0.1723036,\n",
      " 'Loss/regularization_loss': 0.073660165,\n",
      " 'Loss/total_loss': 0.5142659,\n",
      " 'learning_rate': 0.03883856}\n",
      "I1128 22:55:47.348777 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.2683021,\n",
      " 'Loss/localization_loss': 0.1723036,\n",
      " 'Loss/regularization_loss': 0.073660165,\n",
      " 'Loss/total_loss': 0.5142659,\n",
      " 'learning_rate': 0.03883856}\n",
      "INFO:tensorflow:Step 154100 per-step time 2.773s\n",
      "I1128 23:00:24.617952 140606687830976 model_lib_v2.py:698] Step 154100 per-step time 2.773s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.19011782,\n",
      " 'Loss/localization_loss': 0.11518435,\n",
      " 'Loss/regularization_loss': 0.073634446,\n",
      " 'Loss/total_loss': 0.37893665,\n",
      " 'learning_rate': 0.038796343}\n",
      "I1128 23:00:24.618297 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.19011782,\n",
      " 'Loss/localization_loss': 0.11518435,\n",
      " 'Loss/regularization_loss': 0.073634446,\n",
      " 'Loss/total_loss': 0.37893665,\n",
      " 'learning_rate': 0.038796343}\n",
      "INFO:tensorflow:Step 154200 per-step time 2.779s\n",
      "I1128 23:05:02.487183 140606687830976 model_lib_v2.py:698] Step 154200 per-step time 2.779s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.37081355,\n",
      " 'Loss/localization_loss': 0.26834685,\n",
      " 'Loss/regularization_loss': 0.073623456,\n",
      " 'Loss/total_loss': 0.7127838,\n",
      " 'learning_rate': 0.038754124}\n",
      "I1128 23:05:02.487495 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.37081355,\n",
      " 'Loss/localization_loss': 0.26834685,\n",
      " 'Loss/regularization_loss': 0.073623456,\n",
      " 'Loss/total_loss': 0.7127838,\n",
      " 'learning_rate': 0.038754124}\n",
      "INFO:tensorflow:Step 154300 per-step time 2.765s\n",
      "I1128 23:09:38.998682 140606687830976 model_lib_v2.py:698] Step 154300 per-step time 2.765s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.24796315,\n",
      " 'Loss/localization_loss': 0.11027353,\n",
      " 'Loss/regularization_loss': 0.073612,\n",
      " 'Loss/total_loss': 0.43184868,\n",
      " 'learning_rate': 0.0387119}\n",
      "I1128 23:09:38.998991 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.24796315,\n",
      " 'Loss/localization_loss': 0.11027353,\n",
      " 'Loss/regularization_loss': 0.073612,\n",
      " 'Loss/total_loss': 0.43184868,\n",
      " 'learning_rate': 0.0387119}\n",
      "INFO:tensorflow:Step 154400 per-step time 2.768s\n",
      "I1128 23:14:15.792673 140606687830976 model_lib_v2.py:698] Step 154400 per-step time 2.768s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2954877,\n",
      " 'Loss/localization_loss': 0.21370095,\n",
      " 'Loss/regularization_loss': 0.073594004,\n",
      " 'Loss/total_loss': 0.5827826,\n",
      " 'learning_rate': 0.038669687}\n",
      "I1128 23:14:15.793005 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.2954877,\n",
      " 'Loss/localization_loss': 0.21370095,\n",
      " 'Loss/regularization_loss': 0.073594004,\n",
      " 'Loss/total_loss': 0.5827826,\n",
      " 'learning_rate': 0.038669687}\n",
      "INFO:tensorflow:Step 154500 per-step time 2.770s\n",
      "I1128 23:18:52.811635 140606687830976 model_lib_v2.py:698] Step 154500 per-step time 2.770s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.19298494,\n",
      " 'Loss/localization_loss': 0.0875265,\n",
      " 'Loss/regularization_loss': 0.07356996,\n",
      " 'Loss/total_loss': 0.3540814,\n",
      " 'learning_rate': 0.03862747}\n",
      "I1128 23:18:52.811949 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.19298494,\n",
      " 'Loss/localization_loss': 0.0875265,\n",
      " 'Loss/regularization_loss': 0.07356996,\n",
      " 'Loss/total_loss': 0.3540814,\n",
      " 'learning_rate': 0.03862747}\n",
      "INFO:tensorflow:Step 154600 per-step time 2.774s\n",
      "I1128 23:23:30.232965 140606687830976 model_lib_v2.py:698] Step 154600 per-step time 2.774s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.20277263,\n",
      " 'Loss/localization_loss': 0.0718091,\n",
      " 'Loss/regularization_loss': 0.07354,\n",
      " 'Loss/total_loss': 0.34812176,\n",
      " 'learning_rate': 0.038585253}\n",
      "I1128 23:23:30.233291 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.20277263,\n",
      " 'Loss/localization_loss': 0.0718091,\n",
      " 'Loss/regularization_loss': 0.07354,\n",
      " 'Loss/total_loss': 0.34812176,\n",
      " 'learning_rate': 0.038585253}\n",
      "INFO:tensorflow:Step 154700 per-step time 2.764s\n",
      "I1128 23:28:06.645034 140606687830976 model_lib_v2.py:698] Step 154700 per-step time 2.764s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2748992,\n",
      " 'Loss/localization_loss': 0.11451591,\n",
      " 'Loss/regularization_loss': 0.07351501,\n",
      " 'Loss/total_loss': 0.46293014,\n",
      " 'learning_rate': 0.03854304}\n",
      "I1128 23:28:06.645344 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.2748992,\n",
      " 'Loss/localization_loss': 0.11451591,\n",
      " 'Loss/regularization_loss': 0.07351501,\n",
      " 'Loss/total_loss': 0.46293014,\n",
      " 'learning_rate': 0.03854304}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 154800 per-step time 2.766s\n",
      "I1128 23:32:43.245316 140606687830976 model_lib_v2.py:698] Step 154800 per-step time 2.766s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.36364332,\n",
      " 'Loss/localization_loss': 0.19847362,\n",
      " 'Loss/regularization_loss': 0.0734893,\n",
      " 'Loss/total_loss': 0.6356062,\n",
      " 'learning_rate': 0.038500834}\n",
      "I1128 23:32:43.245640 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.36364332,\n",
      " 'Loss/localization_loss': 0.19847362,\n",
      " 'Loss/regularization_loss': 0.0734893,\n",
      " 'Loss/total_loss': 0.6356062,\n",
      " 'learning_rate': 0.038500834}\n",
      "INFO:tensorflow:Step 154900 per-step time 2.771s\n",
      "I1128 23:37:20.330112 140606687830976 model_lib_v2.py:698] Step 154900 per-step time 2.771s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.24042675,\n",
      " 'Loss/localization_loss': 0.13709314,\n",
      " 'Loss/regularization_loss': 0.07346361,\n",
      " 'Loss/total_loss': 0.45098352,\n",
      " 'learning_rate': 0.038458627}\n",
      "I1128 23:37:20.330425 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.24042675,\n",
      " 'Loss/localization_loss': 0.13709314,\n",
      " 'Loss/regularization_loss': 0.07346361,\n",
      " 'Loss/total_loss': 0.45098352,\n",
      " 'learning_rate': 0.038458627}\n",
      "INFO:tensorflow:Step 155000 per-step time 2.764s\n",
      "I1128 23:41:56.718635 140606687830976 model_lib_v2.py:698] Step 155000 per-step time 2.764s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17175113,\n",
      " 'Loss/localization_loss': 0.07434499,\n",
      " 'Loss/regularization_loss': 0.07343218,\n",
      " 'Loss/total_loss': 0.31952828,\n",
      " 'learning_rate': 0.038416415}\n",
      "I1128 23:41:56.718944 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.17175113,\n",
      " 'Loss/localization_loss': 0.07434499,\n",
      " 'Loss/regularization_loss': 0.07343218,\n",
      " 'Loss/total_loss': 0.31952828,\n",
      " 'learning_rate': 0.038416415}\n",
      "INFO:tensorflow:Step 155100 per-step time 2.771s\n",
      "I1128 23:46:33.816502 140606687830976 model_lib_v2.py:698] Step 155100 per-step time 2.771s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.29006857,\n",
      " 'Loss/localization_loss': 0.16435103,\n",
      " 'Loss/regularization_loss': 0.07340109,\n",
      " 'Loss/total_loss': 0.5278207,\n",
      " 'learning_rate': 0.038374208}\n",
      "I1128 23:46:33.816829 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.29006857,\n",
      " 'Loss/localization_loss': 0.16435103,\n",
      " 'Loss/regularization_loss': 0.07340109,\n",
      " 'Loss/total_loss': 0.5278207,\n",
      " 'learning_rate': 0.038374208}\n",
      "INFO:tensorflow:Step 155200 per-step time 2.768s\n",
      "I1128 23:51:10.640245 140606687830976 model_lib_v2.py:698] Step 155200 per-step time 2.768s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1596493,\n",
      " 'Loss/localization_loss': 0.055219296,\n",
      " 'Loss/regularization_loss': 0.07336618,\n",
      " 'Loss/total_loss': 0.28823477,\n",
      " 'learning_rate': 0.038332004}\n",
      "I1128 23:51:10.640552 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.1596493,\n",
      " 'Loss/localization_loss': 0.055219296,\n",
      " 'Loss/regularization_loss': 0.07336618,\n",
      " 'Loss/total_loss': 0.28823477,\n",
      " 'learning_rate': 0.038332004}\n",
      "INFO:tensorflow:Step 155300 per-step time 2.767s\n",
      "I1128 23:55:47.369080 140606687830976 model_lib_v2.py:698] Step 155300 per-step time 2.767s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2207979,\n",
      " 'Loss/localization_loss': 0.12069449,\n",
      " 'Loss/regularization_loss': 0.07332891,\n",
      " 'Loss/total_loss': 0.4148213,\n",
      " 'learning_rate': 0.038289804}\n",
      "I1128 23:55:47.369419 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.2207979,\n",
      " 'Loss/localization_loss': 0.12069449,\n",
      " 'Loss/regularization_loss': 0.07332891,\n",
      " 'Loss/total_loss': 0.4148213,\n",
      " 'learning_rate': 0.038289804}\n",
      "INFO:tensorflow:Step 155400 per-step time 2.767s\n",
      "I1129 00:00:24.072602 140606687830976 model_lib_v2.py:698] Step 155400 per-step time 2.767s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.23338865,\n",
      " 'Loss/localization_loss': 0.11386831,\n",
      " 'Loss/regularization_loss': 0.07329826,\n",
      " 'Loss/total_loss': 0.42055523,\n",
      " 'learning_rate': 0.0382476}\n",
      "I1129 00:00:24.072935 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.23338865,\n",
      " 'Loss/localization_loss': 0.11386831,\n",
      " 'Loss/regularization_loss': 0.07329826,\n",
      " 'Loss/total_loss': 0.42055523,\n",
      " 'learning_rate': 0.0382476}\n",
      "INFO:tensorflow:Step 155500 per-step time 2.766s\n",
      "I1129 00:05:00.670021 140606687830976 model_lib_v2.py:698] Step 155500 per-step time 2.766s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.20233162,\n",
      " 'Loss/localization_loss': 0.1434428,\n",
      " 'Loss/regularization_loss': 0.073264815,\n",
      " 'Loss/total_loss': 0.41903925,\n",
      " 'learning_rate': 0.038205404}\n",
      "I1129 00:05:00.670340 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.20233162,\n",
      " 'Loss/localization_loss': 0.1434428,\n",
      " 'Loss/regularization_loss': 0.073264815,\n",
      " 'Loss/total_loss': 0.41903925,\n",
      " 'learning_rate': 0.038205404}\n",
      "INFO:tensorflow:Step 155600 per-step time 2.769s\n",
      "I1129 00:09:37.559428 140606687830976 model_lib_v2.py:698] Step 155600 per-step time 2.769s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14821483,\n",
      " 'Loss/localization_loss': 0.06431374,\n",
      " 'Loss/regularization_loss': 0.07323567,\n",
      " 'Loss/total_loss': 0.28576425,\n",
      " 'learning_rate': 0.038163207}\n",
      "I1129 00:09:37.559738 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.14821483,\n",
      " 'Loss/localization_loss': 0.06431374,\n",
      " 'Loss/regularization_loss': 0.07323567,\n",
      " 'Loss/total_loss': 0.28576425,\n",
      " 'learning_rate': 0.038163207}\n",
      "INFO:tensorflow:Step 155700 per-step time 2.767s\n",
      "I1129 00:14:14.295410 140606687830976 model_lib_v2.py:698] Step 155700 per-step time 2.767s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15301743,\n",
      " 'Loss/localization_loss': 0.044831872,\n",
      " 'Loss/regularization_loss': 0.07319739,\n",
      " 'Loss/total_loss': 0.2710467,\n",
      " 'learning_rate': 0.038121015}\n",
      "I1129 00:14:14.295728 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.15301743,\n",
      " 'Loss/localization_loss': 0.044831872,\n",
      " 'Loss/regularization_loss': 0.07319739,\n",
      " 'Loss/total_loss': 0.2710467,\n",
      " 'learning_rate': 0.038121015}\n",
      "INFO:tensorflow:Step 155800 per-step time 2.763s\n",
      "I1129 00:18:50.579625 140606687830976 model_lib_v2.py:698] Step 155800 per-step time 2.763s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13863511,\n",
      " 'Loss/localization_loss': 0.05102897,\n",
      " 'Loss/regularization_loss': 0.073154815,\n",
      " 'Loss/total_loss': 0.2628189,\n",
      " 'learning_rate': 0.03807882}\n",
      "I1129 00:18:50.579959 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.13863511,\n",
      " 'Loss/localization_loss': 0.05102897,\n",
      " 'Loss/regularization_loss': 0.073154815,\n",
      " 'Loss/total_loss': 0.2628189,\n",
      " 'learning_rate': 0.03807882}\n",
      "INFO:tensorflow:Step 155900 per-step time 2.766s\n",
      "I1129 00:23:27.219476 140606687830976 model_lib_v2.py:698] Step 155900 per-step time 2.766s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11391989,\n",
      " 'Loss/localization_loss': 0.029275771,\n",
      " 'Loss/regularization_loss': 0.07311188,\n",
      " 'Loss/total_loss': 0.21630755,\n",
      " 'learning_rate': 0.038036633}\n",
      "I1129 00:23:27.219789 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.11391989,\n",
      " 'Loss/localization_loss': 0.029275771,\n",
      " 'Loss/regularization_loss': 0.07311188,\n",
      " 'Loss/total_loss': 0.21630755,\n",
      " 'learning_rate': 0.038036633}\n",
      "INFO:tensorflow:Step 156000 per-step time 2.766s\n",
      "I1129 00:28:03.867774 140606687830976 model_lib_v2.py:698] Step 156000 per-step time 2.766s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17449316,\n",
      " 'Loss/localization_loss': 0.054053083,\n",
      " 'Loss/regularization_loss': 0.073058575,\n",
      " 'Loss/total_loss': 0.3016048,\n",
      " 'learning_rate': 0.03799444}\n",
      "I1129 00:28:03.868106 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.17449316,\n",
      " 'Loss/localization_loss': 0.054053083,\n",
      " 'Loss/regularization_loss': 0.073058575,\n",
      " 'Loss/total_loss': 0.3016048,\n",
      " 'learning_rate': 0.03799444}\n",
      "INFO:tensorflow:Step 156100 per-step time 2.780s\n",
      "I1129 00:32:41.866308 140606687830976 model_lib_v2.py:698] Step 156100 per-step time 2.780s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09624071,\n",
      " 'Loss/localization_loss': 0.021004079,\n",
      " 'Loss/regularization_loss': 0.07300104,\n",
      " 'Loss/total_loss': 0.19024584,\n",
      " 'learning_rate': 0.03795226}\n",
      "I1129 00:32:41.866630 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.09624071,\n",
      " 'Loss/localization_loss': 0.021004079,\n",
      " 'Loss/regularization_loss': 0.07300104,\n",
      " 'Loss/total_loss': 0.19024584,\n",
      " 'learning_rate': 0.03795226}\n",
      "INFO:tensorflow:Step 156200 per-step time 2.772s\n",
      "I1129 00:37:19.034123 140606687830976 model_lib_v2.py:698] Step 156200 per-step time 2.772s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11240031,\n",
      " 'Loss/localization_loss': 0.03608115,\n",
      " 'Loss/regularization_loss': 0.0729412,\n",
      " 'Loss/total_loss': 0.22142266,\n",
      " 'learning_rate': 0.03791007}\n",
      "I1129 00:37:19.034439 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.11240031,\n",
      " 'Loss/localization_loss': 0.03608115,\n",
      " 'Loss/regularization_loss': 0.0729412,\n",
      " 'Loss/total_loss': 0.22142266,\n",
      " 'learning_rate': 0.03791007}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 156300 per-step time 2.778s\n",
      "I1129 00:41:56.872743 140606687830976 model_lib_v2.py:698] Step 156300 per-step time 2.778s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.20736519,\n",
      " 'Loss/localization_loss': 0.05996135,\n",
      " 'Loss/regularization_loss': 0.07288544,\n",
      " 'Loss/total_loss': 0.34021196,\n",
      " 'learning_rate': 0.037867893}\n",
      "I1129 00:41:56.873074 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.20736519,\n",
      " 'Loss/localization_loss': 0.05996135,\n",
      " 'Loss/regularization_loss': 0.07288544,\n",
      " 'Loss/total_loss': 0.34021196,\n",
      " 'learning_rate': 0.037867893}\n",
      "INFO:tensorflow:Step 156400 per-step time 2.773s\n",
      "I1129 00:46:34.138980 140606687830976 model_lib_v2.py:698] Step 156400 per-step time 2.773s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16815989,\n",
      " 'Loss/localization_loss': 0.072470464,\n",
      " 'Loss/regularization_loss': 0.07283098,\n",
      " 'Loss/total_loss': 0.31346133,\n",
      " 'learning_rate': 0.037825715}\n",
      "I1129 00:46:34.139299 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.16815989,\n",
      " 'Loss/localization_loss': 0.072470464,\n",
      " 'Loss/regularization_loss': 0.07283098,\n",
      " 'Loss/total_loss': 0.31346133,\n",
      " 'learning_rate': 0.037825715}\n",
      "INFO:tensorflow:Step 156500 per-step time 2.769s\n",
      "I1129 00:51:11.040370 140606687830976 model_lib_v2.py:698] Step 156500 per-step time 2.769s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13477533,\n",
      " 'Loss/localization_loss': 0.033136304,\n",
      " 'Loss/regularization_loss': 0.07276876,\n",
      " 'Loss/total_loss': 0.2406804,\n",
      " 'learning_rate': 0.03778354}\n",
      "I1129 00:51:11.040691 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.13477533,\n",
      " 'Loss/localization_loss': 0.033136304,\n",
      " 'Loss/regularization_loss': 0.07276876,\n",
      " 'Loss/total_loss': 0.2406804,\n",
      " 'learning_rate': 0.03778354}\n",
      "INFO:tensorflow:Step 156600 per-step time 2.767s\n",
      "I1129 00:55:47.731928 140606687830976 model_lib_v2.py:698] Step 156600 per-step time 2.767s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.22928016,\n",
      " 'Loss/localization_loss': 0.08162646,\n",
      " 'Loss/regularization_loss': 0.0727104,\n",
      " 'Loss/total_loss': 0.38361704,\n",
      " 'learning_rate': 0.037741363}\n",
      "I1129 00:55:47.732259 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.22928016,\n",
      " 'Loss/localization_loss': 0.08162646,\n",
      " 'Loss/regularization_loss': 0.0727104,\n",
      " 'Loss/total_loss': 0.38361704,\n",
      " 'learning_rate': 0.037741363}\n",
      "INFO:tensorflow:Step 156700 per-step time 2.776s\n",
      "I1129 01:00:25.312571 140606687830976 model_lib_v2.py:698] Step 156700 per-step time 2.776s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15979423,\n",
      " 'Loss/localization_loss': 0.0709477,\n",
      " 'Loss/regularization_loss': 0.072652474,\n",
      " 'Loss/total_loss': 0.3033944,\n",
      " 'learning_rate': 0.037699193}\n",
      "I1129 01:00:25.312905 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.15979423,\n",
      " 'Loss/localization_loss': 0.0709477,\n",
      " 'Loss/regularization_loss': 0.072652474,\n",
      " 'Loss/total_loss': 0.3033944,\n",
      " 'learning_rate': 0.037699193}\n",
      "INFO:tensorflow:Step 156800 per-step time 2.779s\n",
      "I1129 01:05:03.184693 140606687830976 model_lib_v2.py:698] Step 156800 per-step time 2.779s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.19411393,\n",
      " 'Loss/localization_loss': 0.086838566,\n",
      " 'Loss/regularization_loss': 0.0726119,\n",
      " 'Loss/total_loss': 0.3535644,\n",
      " 'learning_rate': 0.037657026}\n",
      "I1129 01:05:03.185014 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.19411393,\n",
      " 'Loss/localization_loss': 0.086838566,\n",
      " 'Loss/regularization_loss': 0.0726119,\n",
      " 'Loss/total_loss': 0.3535644,\n",
      " 'learning_rate': 0.037657026}\n",
      "INFO:tensorflow:Step 156900 per-step time 2.762s\n",
      "I1129 01:09:39.365841 140606687830976 model_lib_v2.py:698] Step 156900 per-step time 2.762s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1828408,\n",
      " 'Loss/localization_loss': 0.0805219,\n",
      " 'Loss/regularization_loss': 0.072588176,\n",
      " 'Loss/total_loss': 0.33595085,\n",
      " 'learning_rate': 0.037614863}\n",
      "I1129 01:09:39.366156 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.1828408,\n",
      " 'Loss/localization_loss': 0.0805219,\n",
      " 'Loss/regularization_loss': 0.072588176,\n",
      " 'Loss/total_loss': 0.33595085,\n",
      " 'learning_rate': 0.037614863}\n",
      "INFO:tensorflow:Step 157000 per-step time 2.770s\n",
      "I1129 01:14:16.391953 140606687830976 model_lib_v2.py:698] Step 157000 per-step time 2.770s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.21212435,\n",
      " 'Loss/localization_loss': 0.10802545,\n",
      " 'Loss/regularization_loss': 0.07256703,\n",
      " 'Loss/total_loss': 0.39271683,\n",
      " 'learning_rate': 0.03757269}\n",
      "I1129 01:14:16.392267 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.21212435,\n",
      " 'Loss/localization_loss': 0.10802545,\n",
      " 'Loss/regularization_loss': 0.07256703,\n",
      " 'Loss/total_loss': 0.39271683,\n",
      " 'learning_rate': 0.03757269}\n",
      "INFO:tensorflow:Step 157100 per-step time 2.785s\n",
      "I1129 01:18:54.867792 140606687830976 model_lib_v2.py:698] Step 157100 per-step time 2.785s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.22605789,\n",
      " 'Loss/localization_loss': 0.10019459,\n",
      " 'Loss/regularization_loss': 0.072546884,\n",
      " 'Loss/total_loss': 0.39879936,\n",
      " 'learning_rate': 0.03753053}\n",
      "I1129 01:18:54.868115 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.22605789,\n",
      " 'Loss/localization_loss': 0.10019459,\n",
      " 'Loss/regularization_loss': 0.072546884,\n",
      " 'Loss/total_loss': 0.39879936,\n",
      " 'learning_rate': 0.03753053}\n",
      "INFO:tensorflow:Step 157200 per-step time 2.773s\n",
      "I1129 01:23:32.203492 140606687830976 model_lib_v2.py:698] Step 157200 per-step time 2.773s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.20515932,\n",
      " 'Loss/localization_loss': 0.11747739,\n",
      " 'Loss/regularization_loss': 0.07252468,\n",
      " 'Loss/total_loss': 0.3951614,\n",
      " 'learning_rate': 0.037488375}\n",
      "I1129 01:23:32.203804 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.20515932,\n",
      " 'Loss/localization_loss': 0.11747739,\n",
      " 'Loss/regularization_loss': 0.07252468,\n",
      " 'Loss/total_loss': 0.3951614,\n",
      " 'learning_rate': 0.037488375}\n",
      "INFO:tensorflow:Step 157300 per-step time 2.770s\n",
      "I1129 01:28:09.229965 140606687830976 model_lib_v2.py:698] Step 157300 per-step time 2.770s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.26204306,\n",
      " 'Loss/localization_loss': 0.15985207,\n",
      " 'Loss/regularization_loss': 0.072504506,\n",
      " 'Loss/total_loss': 0.49439967,\n",
      " 'learning_rate': 0.037446223}\n",
      "I1129 01:28:09.230279 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.26204306,\n",
      " 'Loss/localization_loss': 0.15985207,\n",
      " 'Loss/regularization_loss': 0.072504506,\n",
      " 'Loss/total_loss': 0.49439967,\n",
      " 'learning_rate': 0.037446223}\n",
      "INFO:tensorflow:Step 157400 per-step time 2.768s\n",
      "I1129 01:32:45.998237 140606687830976 model_lib_v2.py:698] Step 157400 per-step time 2.768s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.19335681,\n",
      " 'Loss/localization_loss': 0.0846036,\n",
      " 'Loss/regularization_loss': 0.07248035,\n",
      " 'Loss/total_loss': 0.35044077,\n",
      " 'learning_rate': 0.037404068}\n",
      "I1129 01:32:45.998547 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.19335681,\n",
      " 'Loss/localization_loss': 0.0846036,\n",
      " 'Loss/regularization_loss': 0.07248035,\n",
      " 'Loss/total_loss': 0.35044077,\n",
      " 'learning_rate': 0.037404068}\n",
      "INFO:tensorflow:Step 157500 per-step time 2.777s\n",
      "I1129 01:37:23.696456 140606687830976 model_lib_v2.py:698] Step 157500 per-step time 2.777s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.22334906,\n",
      " 'Loss/localization_loss': 0.095248096,\n",
      " 'Loss/regularization_loss': 0.07245763,\n",
      " 'Loss/total_loss': 0.3910548,\n",
      " 'learning_rate': 0.03736192}\n",
      "I1129 01:37:23.696763 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.22334906,\n",
      " 'Loss/localization_loss': 0.095248096,\n",
      " 'Loss/regularization_loss': 0.07245763,\n",
      " 'Loss/total_loss': 0.3910548,\n",
      " 'learning_rate': 0.03736192}\n",
      "INFO:tensorflow:Step 157600 per-step time 2.768s\n",
      "I1129 01:42:00.529166 140606687830976 model_lib_v2.py:698] Step 157600 per-step time 2.768s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.24738936,\n",
      " 'Loss/localization_loss': 0.12929152,\n",
      " 'Loss/regularization_loss': 0.072429284,\n",
      " 'Loss/total_loss': 0.44911015,\n",
      " 'learning_rate': 0.037319772}\n",
      "I1129 01:42:00.529515 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.24738936,\n",
      " 'Loss/localization_loss': 0.12929152,\n",
      " 'Loss/regularization_loss': 0.072429284,\n",
      " 'Loss/total_loss': 0.44911015,\n",
      " 'learning_rate': 0.037319772}\n",
      "INFO:tensorflow:Step 157700 per-step time 2.771s\n",
      "I1129 01:46:37.583296 140606687830976 model_lib_v2.py:698] Step 157700 per-step time 2.771s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.36304942,\n",
      " 'Loss/localization_loss': 0.18634062,\n",
      " 'Loss/regularization_loss': 0.07240129,\n",
      " 'Loss/total_loss': 0.6217913,\n",
      " 'learning_rate': 0.03727763}\n",
      "I1129 01:46:37.583610 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.36304942,\n",
      " 'Loss/localization_loss': 0.18634062,\n",
      " 'Loss/regularization_loss': 0.07240129,\n",
      " 'Loss/total_loss': 0.6217913,\n",
      " 'learning_rate': 0.03727763}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 157800 per-step time 2.774s\n",
      "I1129 01:51:14.945147 140606687830976 model_lib_v2.py:698] Step 157800 per-step time 2.774s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.23220256,\n",
      " 'Loss/localization_loss': 0.15405294,\n",
      " 'Loss/regularization_loss': 0.07237063,\n",
      " 'Loss/total_loss': 0.45862612,\n",
      " 'learning_rate': 0.037235487}\n",
      "I1129 01:51:14.945476 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.23220256,\n",
      " 'Loss/localization_loss': 0.15405294,\n",
      " 'Loss/regularization_loss': 0.07237063,\n",
      " 'Loss/total_loss': 0.45862612,\n",
      " 'learning_rate': 0.037235487}\n",
      "INFO:tensorflow:Step 157900 per-step time 2.777s\n",
      "I1129 01:55:52.690560 140606687830976 model_lib_v2.py:698] Step 157900 per-step time 2.777s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.30285648,\n",
      " 'Loss/localization_loss': 0.15114395,\n",
      " 'Loss/regularization_loss': 0.07235361,\n",
      " 'Loss/total_loss': 0.526354,\n",
      " 'learning_rate': 0.03719335}\n",
      "I1129 01:55:52.690895 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.30285648,\n",
      " 'Loss/localization_loss': 0.15114395,\n",
      " 'Loss/regularization_loss': 0.07235361,\n",
      " 'Loss/total_loss': 0.526354,\n",
      " 'learning_rate': 0.03719335}\n",
      "INFO:tensorflow:Step 158000 per-step time 2.771s\n",
      "I1129 02:00:29.834464 140606687830976 model_lib_v2.py:698] Step 158000 per-step time 2.771s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.24229077,\n",
      " 'Loss/localization_loss': 0.106451996,\n",
      " 'Loss/regularization_loss': 0.072330385,\n",
      " 'Loss/total_loss': 0.42107314,\n",
      " 'learning_rate': 0.03715122}\n",
      "I1129 02:00:29.834777 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.24229077,\n",
      " 'Loss/localization_loss': 0.106451996,\n",
      " 'Loss/regularization_loss': 0.072330385,\n",
      " 'Loss/total_loss': 0.42107314,\n",
      " 'learning_rate': 0.03715122}\n",
      "INFO:tensorflow:Step 158100 per-step time 2.791s\n",
      "I1129 02:05:08.916125 140606687830976 model_lib_v2.py:698] Step 158100 per-step time 2.791s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3825283,\n",
      " 'Loss/localization_loss': 0.23838775,\n",
      " 'Loss/regularization_loss': 0.072331175,\n",
      " 'Loss/total_loss': 0.69324726,\n",
      " 'learning_rate': 0.037109084}\n",
      "I1129 02:05:08.916467 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.3825283,\n",
      " 'Loss/localization_loss': 0.23838775,\n",
      " 'Loss/regularization_loss': 0.072331175,\n",
      " 'Loss/total_loss': 0.69324726,\n",
      " 'learning_rate': 0.037109084}\n",
      "INFO:tensorflow:Step 158200 per-step time 2.766s\n",
      "I1129 02:09:45.515819 140606687830976 model_lib_v2.py:698] Step 158200 per-step time 2.766s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.18864673,\n",
      " 'Loss/localization_loss': 0.049943205,\n",
      " 'Loss/regularization_loss': 0.07233912,\n",
      " 'Loss/total_loss': 0.31092906,\n",
      " 'learning_rate': 0.037066955}\n",
      "I1129 02:09:45.516147 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.18864673,\n",
      " 'Loss/localization_loss': 0.049943205,\n",
      " 'Loss/regularization_loss': 0.07233912,\n",
      " 'Loss/total_loss': 0.31092906,\n",
      " 'learning_rate': 0.037066955}\n",
      "INFO:tensorflow:Step 158300 per-step time 2.772s\n",
      "I1129 02:14:22.678157 140606687830976 model_lib_v2.py:698] Step 158300 per-step time 2.772s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.35025868,\n",
      " 'Loss/localization_loss': 0.09211643,\n",
      " 'Loss/regularization_loss': 0.07235799,\n",
      " 'Loss/total_loss': 0.5147331,\n",
      " 'learning_rate': 0.037024833}\n",
      "I1129 02:14:22.678467 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.35025868,\n",
      " 'Loss/localization_loss': 0.09211643,\n",
      " 'Loss/regularization_loss': 0.07235799,\n",
      " 'Loss/total_loss': 0.5147331,\n",
      " 'learning_rate': 0.037024833}\n",
      "INFO:tensorflow:Step 158400 per-step time 2.769s\n",
      "I1129 02:18:59.580043 140606687830976 model_lib_v2.py:698] Step 158400 per-step time 2.769s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15145212,\n",
      " 'Loss/localization_loss': 0.046453744,\n",
      " 'Loss/regularization_loss': 0.072371185,\n",
      " 'Loss/total_loss': 0.27027705,\n",
      " 'learning_rate': 0.03698271}\n",
      "I1129 02:18:59.580351 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.15145212,\n",
      " 'Loss/localization_loss': 0.046453744,\n",
      " 'Loss/regularization_loss': 0.072371185,\n",
      " 'Loss/total_loss': 0.27027705,\n",
      " 'learning_rate': 0.03698271}\n",
      "INFO:tensorflow:Step 158500 per-step time 2.766s\n",
      "I1129 02:23:36.137843 140606687830976 model_lib_v2.py:698] Step 158500 per-step time 2.766s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2400066,\n",
      " 'Loss/localization_loss': 0.10478408,\n",
      " 'Loss/regularization_loss': 0.07239972,\n",
      " 'Loss/total_loss': 0.41719037,\n",
      " 'learning_rate': 0.036940597}\n",
      "I1129 02:23:36.138197 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.2400066,\n",
      " 'Loss/localization_loss': 0.10478408,\n",
      " 'Loss/regularization_loss': 0.07239972,\n",
      " 'Loss/total_loss': 0.41719037,\n",
      " 'learning_rate': 0.036940597}\n",
      "INFO:tensorflow:Step 158600 per-step time 2.773s\n",
      "I1129 02:28:13.397346 140606687830976 model_lib_v2.py:698] Step 158600 per-step time 2.773s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.41480067,\n",
      " 'Loss/localization_loss': 0.17980622,\n",
      " 'Loss/regularization_loss': 0.07240703,\n",
      " 'Loss/total_loss': 0.66701394,\n",
      " 'learning_rate': 0.03689848}\n",
      "I1129 02:28:13.397687 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.41480067,\n",
      " 'Loss/localization_loss': 0.17980622,\n",
      " 'Loss/regularization_loss': 0.07240703,\n",
      " 'Loss/total_loss': 0.66701394,\n",
      " 'learning_rate': 0.03689848}\n",
      "INFO:tensorflow:Step 158700 per-step time 2.770s\n",
      "I1129 02:32:50.375985 140606687830976 model_lib_v2.py:698] Step 158700 per-step time 2.770s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.22604983,\n",
      " 'Loss/localization_loss': 0.12330226,\n",
      " 'Loss/regularization_loss': 0.07241482,\n",
      " 'Loss/total_loss': 0.4217669,\n",
      " 'learning_rate': 0.03685637}\n",
      "I1129 02:32:50.376287 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.22604983,\n",
      " 'Loss/localization_loss': 0.12330226,\n",
      " 'Loss/regularization_loss': 0.07241482,\n",
      " 'Loss/total_loss': 0.4217669,\n",
      " 'learning_rate': 0.03685637}\n",
      "INFO:tensorflow:Step 158800 per-step time 2.776s\n",
      "I1129 02:37:28.017181 140606687830976 model_lib_v2.py:698] Step 158800 per-step time 2.776s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.21564403,\n",
      " 'Loss/localization_loss': 0.15265098,\n",
      " 'Loss/regularization_loss': 0.07241892,\n",
      " 'Loss/total_loss': 0.44071394,\n",
      " 'learning_rate': 0.036814265}\n",
      "I1129 02:37:28.017523 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.21564403,\n",
      " 'Loss/localization_loss': 0.15265098,\n",
      " 'Loss/regularization_loss': 0.07241892,\n",
      " 'Loss/total_loss': 0.44071394,\n",
      " 'learning_rate': 0.036814265}\n",
      "INFO:tensorflow:Step 158900 per-step time 2.766s\n",
      "I1129 02:42:04.647139 140606687830976 model_lib_v2.py:698] Step 158900 per-step time 2.766s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.36173916,\n",
      " 'Loss/localization_loss': 0.14264046,\n",
      " 'Loss/regularization_loss': 0.07242254,\n",
      " 'Loss/total_loss': 0.57680213,\n",
      " 'learning_rate': 0.03677216}\n",
      "I1129 02:42:04.647477 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.36173916,\n",
      " 'Loss/localization_loss': 0.14264046,\n",
      " 'Loss/regularization_loss': 0.07242254,\n",
      " 'Loss/total_loss': 0.57680213,\n",
      " 'learning_rate': 0.03677216}\n",
      "INFO:tensorflow:Step 159000 per-step time 2.770s\n",
      "I1129 02:46:41.601313 140606687830976 model_lib_v2.py:698] Step 159000 per-step time 2.770s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.33276135,\n",
      " 'Loss/localization_loss': 0.17209285,\n",
      " 'Loss/regularization_loss': 0.07243003,\n",
      " 'Loss/total_loss': 0.5772842,\n",
      " 'learning_rate': 0.03673006}\n",
      "I1129 02:46:41.601650 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.33276135,\n",
      " 'Loss/localization_loss': 0.17209285,\n",
      " 'Loss/regularization_loss': 0.07243003,\n",
      " 'Loss/total_loss': 0.5772842,\n",
      " 'learning_rate': 0.03673006}\n",
      "INFO:tensorflow:Step 159100 per-step time 2.781s\n",
      "I1129 02:51:19.746356 140606687830976 model_lib_v2.py:698] Step 159100 per-step time 2.781s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.18045385,\n",
      " 'Loss/localization_loss': 0.11397816,\n",
      " 'Loss/regularization_loss': 0.072461724,\n",
      " 'Loss/total_loss': 0.3668937,\n",
      " 'learning_rate': 0.03668796}\n",
      "I1129 02:51:19.746707 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.18045385,\n",
      " 'Loss/localization_loss': 0.11397816,\n",
      " 'Loss/regularization_loss': 0.072461724,\n",
      " 'Loss/total_loss': 0.3668937,\n",
      " 'learning_rate': 0.03668796}\n",
      "INFO:tensorflow:Step 159200 per-step time 2.765s\n",
      "I1129 02:55:56.219724 140606687830976 model_lib_v2.py:698] Step 159200 per-step time 2.765s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.41927716,\n",
      " 'Loss/localization_loss': 0.11854823,\n",
      " 'Loss/regularization_loss': 0.0724714,\n",
      " 'Loss/total_loss': 0.6102968,\n",
      " 'learning_rate': 0.036645867}\n",
      "I1129 02:55:56.220037 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.41927716,\n",
      " 'Loss/localization_loss': 0.11854823,\n",
      " 'Loss/regularization_loss': 0.0724714,\n",
      " 'Loss/total_loss': 0.6102968,\n",
      " 'learning_rate': 0.036645867}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 159300 per-step time 2.770s\n",
      "I1129 03:00:33.233980 140606687830976 model_lib_v2.py:698] Step 159300 per-step time 2.770s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.23670009,\n",
      " 'Loss/localization_loss': 0.094357,\n",
      " 'Loss/regularization_loss': 0.07251007,\n",
      " 'Loss/total_loss': 0.40356714,\n",
      " 'learning_rate': 0.03660378}\n",
      "I1129 03:00:33.234314 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.23670009,\n",
      " 'Loss/localization_loss': 0.094357,\n",
      " 'Loss/regularization_loss': 0.07251007,\n",
      " 'Loss/total_loss': 0.40356714,\n",
      " 'learning_rate': 0.03660378}\n",
      "INFO:tensorflow:Step 159400 per-step time 2.768s\n",
      "I1129 03:05:10.023455 140606687830976 model_lib_v2.py:698] Step 159400 per-step time 2.768s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.24437125,\n",
      " 'Loss/localization_loss': 0.115102395,\n",
      " 'Loss/regularization_loss': 0.07255185,\n",
      " 'Loss/total_loss': 0.4320255,\n",
      " 'learning_rate': 0.03656169}\n",
      "I1129 03:05:10.023790 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.24437125,\n",
      " 'Loss/localization_loss': 0.115102395,\n",
      " 'Loss/regularization_loss': 0.07255185,\n",
      " 'Loss/total_loss': 0.4320255,\n",
      " 'learning_rate': 0.03656169}\n",
      "INFO:tensorflow:Step 159500 per-step time 2.765s\n",
      "I1129 03:09:46.495165 140606687830976 model_lib_v2.py:698] Step 159500 per-step time 2.765s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15455681,\n",
      " 'Loss/localization_loss': 0.052520383,\n",
      " 'Loss/regularization_loss': 0.07255892,\n",
      " 'Loss/total_loss': 0.2796361,\n",
      " 'learning_rate': 0.036519613}\n",
      "I1129 03:09:46.495503 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.15455681,\n",
      " 'Loss/localization_loss': 0.052520383,\n",
      " 'Loss/regularization_loss': 0.07255892,\n",
      " 'Loss/total_loss': 0.2796361,\n",
      " 'learning_rate': 0.036519613}\n",
      "INFO:tensorflow:Step 159600 per-step time 2.767s\n",
      "I1129 03:14:23.146232 140606687830976 model_lib_v2.py:698] Step 159600 per-step time 2.767s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.23931359,\n",
      " 'Loss/localization_loss': 0.0897898,\n",
      " 'Loss/regularization_loss': 0.072589755,\n",
      " 'Loss/total_loss': 0.40169317,\n",
      " 'learning_rate': 0.036477536}\n",
      "I1129 03:14:23.146565 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.23931359,\n",
      " 'Loss/localization_loss': 0.0897898,\n",
      " 'Loss/regularization_loss': 0.072589755,\n",
      " 'Loss/total_loss': 0.40169317,\n",
      " 'learning_rate': 0.036477536}\n",
      "INFO:tensorflow:Step 159700 per-step time 2.774s\n",
      "I1129 03:19:00.518469 140606687830976 model_lib_v2.py:698] Step 159700 per-step time 2.774s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.49361014,\n",
      " 'Loss/localization_loss': 0.23339708,\n",
      " 'Loss/regularization_loss': 0.07259044,\n",
      " 'Loss/total_loss': 0.7995977,\n",
      " 'learning_rate': 0.036435463}\n",
      "I1129 03:19:00.518782 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.49361014,\n",
      " 'Loss/localization_loss': 0.23339708,\n",
      " 'Loss/regularization_loss': 0.07259044,\n",
      " 'Loss/total_loss': 0.7995977,\n",
      " 'learning_rate': 0.036435463}\n",
      "INFO:tensorflow:Step 159800 per-step time 2.778s\n",
      "I1129 03:23:38.304563 140606687830976 model_lib_v2.py:698] Step 159800 per-step time 2.778s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.38449425,\n",
      " 'Loss/localization_loss': 0.24322225,\n",
      " 'Loss/regularization_loss': 0.07260133,\n",
      " 'Loss/total_loss': 0.7003178,\n",
      " 'learning_rate': 0.03639339}\n",
      "I1129 03:23:38.304878 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.38449425,\n",
      " 'Loss/localization_loss': 0.24322225,\n",
      " 'Loss/regularization_loss': 0.07260133,\n",
      " 'Loss/total_loss': 0.7003178,\n",
      " 'learning_rate': 0.03639339}\n",
      "INFO:tensorflow:Step 159900 per-step time 2.776s\n",
      "I1129 03:28:15.882859 140606687830976 model_lib_v2.py:698] Step 159900 per-step time 2.776s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3778897,\n",
      " 'Loss/localization_loss': 0.24786204,\n",
      " 'Loss/regularization_loss': 0.0726405,\n",
      " 'Loss/total_loss': 0.6983923,\n",
      " 'learning_rate': 0.036351327}\n",
      "I1129 03:28:15.883166 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.3778897,\n",
      " 'Loss/localization_loss': 0.24786204,\n",
      " 'Loss/regularization_loss': 0.0726405,\n",
      " 'Loss/total_loss': 0.6983923,\n",
      " 'learning_rate': 0.036351327}\n",
      "INFO:tensorflow:Step 160000 per-step time 2.769s\n",
      "I1129 03:32:52.759694 140606687830976 model_lib_v2.py:698] Step 160000 per-step time 2.769s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.27308196,\n",
      " 'Loss/localization_loss': 0.1485248,\n",
      " 'Loss/regularization_loss': 0.0726783,\n",
      " 'Loss/total_loss': 0.49428505,\n",
      " 'learning_rate': 0.036309265}\n",
      "I1129 03:32:52.760003 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.27308196,\n",
      " 'Loss/localization_loss': 0.1485248,\n",
      " 'Loss/regularization_loss': 0.0726783,\n",
      " 'Loss/total_loss': 0.49428505,\n",
      " 'learning_rate': 0.036309265}\n",
      "INFO:tensorflow:Step 160100 per-step time 2.778s\n",
      "I1129 03:37:30.516538 140606687830976 model_lib_v2.py:698] Step 160100 per-step time 2.778s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.30548918,\n",
      " 'Loss/localization_loss': 0.11148398,\n",
      " 'Loss/regularization_loss': 0.0726969,\n",
      " 'Loss/total_loss': 0.48967007,\n",
      " 'learning_rate': 0.036267206}\n",
      "I1129 03:37:30.516860 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.30548918,\n",
      " 'Loss/localization_loss': 0.11148398,\n",
      " 'Loss/regularization_loss': 0.0726969,\n",
      " 'Loss/total_loss': 0.48967007,\n",
      " 'learning_rate': 0.036267206}\n",
      "INFO:tensorflow:Step 160200 per-step time 2.764s\n",
      "I1129 03:42:06.962581 140606687830976 model_lib_v2.py:698] Step 160200 per-step time 2.764s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.33439216,\n",
      " 'Loss/localization_loss': 0.22727624,\n",
      " 'Loss/regularization_loss': 0.072722875,\n",
      " 'Loss/total_loss': 0.6343913,\n",
      " 'learning_rate': 0.036225148}\n",
      "I1129 03:42:06.962894 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.33439216,\n",
      " 'Loss/localization_loss': 0.22727624,\n",
      " 'Loss/regularization_loss': 0.072722875,\n",
      " 'Loss/total_loss': 0.6343913,\n",
      " 'learning_rate': 0.036225148}\n",
      "INFO:tensorflow:Step 160300 per-step time 2.768s\n",
      "I1129 03:46:43.793372 140606687830976 model_lib_v2.py:698] Step 160300 per-step time 2.768s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2855026,\n",
      " 'Loss/localization_loss': 0.1521702,\n",
      " 'Loss/regularization_loss': 0.07275933,\n",
      " 'Loss/total_loss': 0.5104321,\n",
      " 'learning_rate': 0.0361831}\n",
      "I1129 03:46:43.793692 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.2855026,\n",
      " 'Loss/localization_loss': 0.1521702,\n",
      " 'Loss/regularization_loss': 0.07275933,\n",
      " 'Loss/total_loss': 0.5104321,\n",
      " 'learning_rate': 0.0361831}\n",
      "INFO:tensorflow:Step 160400 per-step time 2.762s\n",
      "I1129 03:51:19.988008 140606687830976 model_lib_v2.py:698] Step 160400 per-step time 2.762s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.25940707,\n",
      " 'Loss/localization_loss': 0.14136393,\n",
      " 'Loss/regularization_loss': 0.072787344,\n",
      " 'Loss/total_loss': 0.47355837,\n",
      " 'learning_rate': 0.036141057}\n",
      "I1129 03:51:19.988340 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.25940707,\n",
      " 'Loss/localization_loss': 0.14136393,\n",
      " 'Loss/regularization_loss': 0.072787344,\n",
      " 'Loss/total_loss': 0.47355837,\n",
      " 'learning_rate': 0.036141057}\n",
      "INFO:tensorflow:Step 160500 per-step time 2.765s\n",
      "I1129 03:55:56.533443 140606687830976 model_lib_v2.py:698] Step 160500 per-step time 2.765s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3870249,\n",
      " 'Loss/localization_loss': 0.20728453,\n",
      " 'Loss/regularization_loss': 0.072792314,\n",
      " 'Loss/total_loss': 0.66710174,\n",
      " 'learning_rate': 0.036099017}\n",
      "I1129 03:55:56.533749 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.3870249,\n",
      " 'Loss/localization_loss': 0.20728453,\n",
      " 'Loss/regularization_loss': 0.072792314,\n",
      " 'Loss/total_loss': 0.66710174,\n",
      " 'learning_rate': 0.036099017}\n",
      "INFO:tensorflow:Step 160600 per-step time 2.764s\n",
      "I1129 04:00:32.903185 140606687830976 model_lib_v2.py:698] Step 160600 per-step time 2.764s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3721498,\n",
      " 'Loss/localization_loss': 0.16000064,\n",
      " 'Loss/regularization_loss': 0.07281006,\n",
      " 'Loss/total_loss': 0.6049605,\n",
      " 'learning_rate': 0.036056977}\n",
      "I1129 04:00:32.903501 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.3721498,\n",
      " 'Loss/localization_loss': 0.16000064,\n",
      " 'Loss/regularization_loss': 0.07281006,\n",
      " 'Loss/total_loss': 0.6049605,\n",
      " 'learning_rate': 0.036056977}\n",
      "INFO:tensorflow:Step 160700 per-step time 2.775s\n",
      "I1129 04:05:10.419812 140606687830976 model_lib_v2.py:698] Step 160700 per-step time 2.775s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.34309822,\n",
      " 'Loss/localization_loss': 0.17634887,\n",
      " 'Loss/regularization_loss': 0.07283193,\n",
      " 'Loss/total_loss': 0.592279,\n",
      " 'learning_rate': 0.036014948}\n",
      "I1129 04:05:10.420158 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.34309822,\n",
      " 'Loss/localization_loss': 0.17634887,\n",
      " 'Loss/regularization_loss': 0.07283193,\n",
      " 'Loss/total_loss': 0.592279,\n",
      " 'learning_rate': 0.036014948}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 160800 per-step time 2.782s\n",
      "I1129 04:09:48.626545 140606687830976 model_lib_v2.py:698] Step 160800 per-step time 2.782s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.32200924,\n",
      " 'Loss/localization_loss': 0.21672028,\n",
      " 'Loss/regularization_loss': 0.07285793,\n",
      " 'Loss/total_loss': 0.61158746,\n",
      " 'learning_rate': 0.035972923}\n",
      "I1129 04:09:48.626859 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.32200924,\n",
      " 'Loss/localization_loss': 0.21672028,\n",
      " 'Loss/regularization_loss': 0.07285793,\n",
      " 'Loss/total_loss': 0.61158746,\n",
      " 'learning_rate': 0.035972923}\n",
      "INFO:tensorflow:Step 160900 per-step time 2.763s\n",
      "I1129 04:14:24.889965 140606687830976 model_lib_v2.py:698] Step 160900 per-step time 2.763s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2384045,\n",
      " 'Loss/localization_loss': 0.14679183,\n",
      " 'Loss/regularization_loss': 0.07287284,\n",
      " 'Loss/total_loss': 0.45806915,\n",
      " 'learning_rate': 0.0359309}\n",
      "I1129 04:14:24.890292 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.2384045,\n",
      " 'Loss/localization_loss': 0.14679183,\n",
      " 'Loss/regularization_loss': 0.07287284,\n",
      " 'Loss/total_loss': 0.45806915,\n",
      " 'learning_rate': 0.0359309}\n",
      "INFO:tensorflow:Step 161000 per-step time 2.764s\n",
      "I1129 04:19:01.252091 140606687830976 model_lib_v2.py:698] Step 161000 per-step time 2.764s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3478988,\n",
      " 'Loss/localization_loss': 0.12699294,\n",
      " 'Loss/regularization_loss': 0.07287571,\n",
      " 'Loss/total_loss': 0.54776746,\n",
      " 'learning_rate': 0.03588888}\n",
      "I1129 04:19:01.252410 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.3478988,\n",
      " 'Loss/localization_loss': 0.12699294,\n",
      " 'Loss/regularization_loss': 0.07287571,\n",
      " 'Loss/total_loss': 0.54776746,\n",
      " 'learning_rate': 0.03588888}\n",
      "INFO:tensorflow:Step 161100 per-step time 2.774s\n",
      "I1129 04:23:38.624362 140606687830976 model_lib_v2.py:698] Step 161100 per-step time 2.774s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.21371567,\n",
      " 'Loss/localization_loss': 0.16272157,\n",
      " 'Loss/regularization_loss': 0.072872974,\n",
      " 'Loss/total_loss': 0.4493102,\n",
      " 'learning_rate': 0.035846867}\n",
      "I1129 04:23:38.624702 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.21371567,\n",
      " 'Loss/localization_loss': 0.16272157,\n",
      " 'Loss/regularization_loss': 0.072872974,\n",
      " 'Loss/total_loss': 0.4493102,\n",
      " 'learning_rate': 0.035846867}\n",
      "INFO:tensorflow:Step 161200 per-step time 2.771s\n",
      "I1129 04:28:15.730336 140606687830976 model_lib_v2.py:698] Step 161200 per-step time 2.771s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2847256,\n",
      " 'Loss/localization_loss': 0.13375385,\n",
      " 'Loss/regularization_loss': 0.07286233,\n",
      " 'Loss/total_loss': 0.49134177,\n",
      " 'learning_rate': 0.035804857}\n",
      "I1129 04:28:15.730647 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.2847256,\n",
      " 'Loss/localization_loss': 0.13375385,\n",
      " 'Loss/regularization_loss': 0.07286233,\n",
      " 'Loss/total_loss': 0.49134177,\n",
      " 'learning_rate': 0.035804857}\n",
      "INFO:tensorflow:Step 161300 per-step time 2.778s\n",
      "I1129 04:32:53.508485 140606687830976 model_lib_v2.py:698] Step 161300 per-step time 2.778s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.26638243,\n",
      " 'Loss/localization_loss': 0.1841283,\n",
      " 'Loss/regularization_loss': 0.07285701,\n",
      " 'Loss/total_loss': 0.5233677,\n",
      " 'learning_rate': 0.035762854}\n",
      "I1129 04:32:53.508793 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.26638243,\n",
      " 'Loss/localization_loss': 0.1841283,\n",
      " 'Loss/regularization_loss': 0.07285701,\n",
      " 'Loss/total_loss': 0.5233677,\n",
      " 'learning_rate': 0.035762854}\n",
      "INFO:tensorflow:Step 161400 per-step time 2.783s\n",
      "I1129 04:37:31.836485 140606687830976 model_lib_v2.py:698] Step 161400 per-step time 2.783s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.25619143,\n",
      " 'Loss/localization_loss': 0.1444079,\n",
      " 'Loss/regularization_loss': 0.072837494,\n",
      " 'Loss/total_loss': 0.47343683,\n",
      " 'learning_rate': 0.035720848}\n",
      "I1129 04:37:31.836882 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.25619143,\n",
      " 'Loss/localization_loss': 0.1444079,\n",
      " 'Loss/regularization_loss': 0.072837494,\n",
      " 'Loss/total_loss': 0.47343683,\n",
      " 'learning_rate': 0.035720848}\n",
      "INFO:tensorflow:Step 161500 per-step time 2.780s\n",
      "I1129 04:42:09.795497 140606687830976 model_lib_v2.py:698] Step 161500 per-step time 2.780s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1574955,\n",
      " 'Loss/localization_loss': 0.10140367,\n",
      " 'Loss/regularization_loss': 0.0728186,\n",
      " 'Loss/total_loss': 0.3317178,\n",
      " 'learning_rate': 0.035678856}\n",
      "I1129 04:42:09.795807 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.1574955,\n",
      " 'Loss/localization_loss': 0.10140367,\n",
      " 'Loss/regularization_loss': 0.0728186,\n",
      " 'Loss/total_loss': 0.3317178,\n",
      " 'learning_rate': 0.035678856}\n",
      "INFO:tensorflow:Step 161600 per-step time 2.766s\n",
      "I1129 04:46:46.400478 140606687830976 model_lib_v2.py:698] Step 161600 per-step time 2.766s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.25531444,\n",
      " 'Loss/localization_loss': 0.15779677,\n",
      " 'Loss/regularization_loss': 0.072805494,\n",
      " 'Loss/total_loss': 0.4859167,\n",
      " 'learning_rate': 0.03563687}\n",
      "I1129 04:46:46.400785 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.25531444,\n",
      " 'Loss/localization_loss': 0.15779677,\n",
      " 'Loss/regularization_loss': 0.072805494,\n",
      " 'Loss/total_loss': 0.4859167,\n",
      " 'learning_rate': 0.03563687}\n",
      "INFO:tensorflow:Step 161700 per-step time 2.780s\n",
      "I1129 04:51:24.435654 140606687830976 model_lib_v2.py:698] Step 161700 per-step time 2.780s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2833779,\n",
      " 'Loss/localization_loss': 0.1976859,\n",
      " 'Loss/regularization_loss': 0.072793916,\n",
      " 'Loss/total_loss': 0.5538577,\n",
      " 'learning_rate': 0.03559488}\n",
      "I1129 04:51:24.435965 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.2833779,\n",
      " 'Loss/localization_loss': 0.1976859,\n",
      " 'Loss/regularization_loss': 0.072793916,\n",
      " 'Loss/total_loss': 0.5538577,\n",
      " 'learning_rate': 0.03559488}\n",
      "INFO:tensorflow:Step 161800 per-step time 2.770s\n",
      "I1129 04:56:01.483724 140606687830976 model_lib_v2.py:698] Step 161800 per-step time 2.770s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.37762907,\n",
      " 'Loss/localization_loss': 0.23876683,\n",
      " 'Loss/regularization_loss': 0.07278457,\n",
      " 'Loss/total_loss': 0.6891805,\n",
      " 'learning_rate': 0.0355529}\n",
      "I1129 04:56:01.484023 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.37762907,\n",
      " 'Loss/localization_loss': 0.23876683,\n",
      " 'Loss/regularization_loss': 0.07278457,\n",
      " 'Loss/total_loss': 0.6891805,\n",
      " 'learning_rate': 0.0355529}\n",
      "INFO:tensorflow:Step 161900 per-step time 2.775s\n",
      "I1129 05:00:38.975520 140606687830976 model_lib_v2.py:698] Step 161900 per-step time 2.775s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.28286758,\n",
      " 'Loss/localization_loss': 0.18705198,\n",
      " 'Loss/regularization_loss': 0.07276887,\n",
      " 'Loss/total_loss': 0.5426884,\n",
      " 'learning_rate': 0.035510924}\n",
      "I1129 05:00:38.975847 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.28286758,\n",
      " 'Loss/localization_loss': 0.18705198,\n",
      " 'Loss/regularization_loss': 0.07276887,\n",
      " 'Loss/total_loss': 0.5426884,\n",
      " 'learning_rate': 0.035510924}\n",
      "INFO:tensorflow:Step 162000 per-step time 2.770s\n",
      "I1129 05:05:16.000474 140606687830976 model_lib_v2.py:698] Step 162000 per-step time 2.770s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.38764116,\n",
      " 'Loss/localization_loss': 0.20143464,\n",
      " 'Loss/regularization_loss': 0.072757944,\n",
      " 'Loss/total_loss': 0.66183376,\n",
      " 'learning_rate': 0.03546896}\n",
      "I1129 05:05:16.000794 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.38764116,\n",
      " 'Loss/localization_loss': 0.20143464,\n",
      " 'Loss/regularization_loss': 0.072757944,\n",
      " 'Loss/total_loss': 0.66183376,\n",
      " 'learning_rate': 0.03546896}\n",
      "INFO:tensorflow:Step 162100 per-step time 2.778s\n",
      "I1129 05:09:53.781618 140606687830976 model_lib_v2.py:698] Step 162100 per-step time 2.778s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.27318946,\n",
      " 'Loss/localization_loss': 0.17983045,\n",
      " 'Loss/regularization_loss': 0.072740324,\n",
      " 'Loss/total_loss': 0.52576023,\n",
      " 'learning_rate': 0.03542699}\n",
      "I1129 05:09:53.781948 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.27318946,\n",
      " 'Loss/localization_loss': 0.17983045,\n",
      " 'Loss/regularization_loss': 0.072740324,\n",
      " 'Loss/total_loss': 0.52576023,\n",
      " 'learning_rate': 0.03542699}\n",
      "INFO:tensorflow:Step 162200 per-step time 2.776s\n",
      "I1129 05:14:31.411873 140606687830976 model_lib_v2.py:698] Step 162200 per-step time 2.776s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.24219017,\n",
      " 'Loss/localization_loss': 0.15951906,\n",
      " 'Loss/regularization_loss': 0.072732225,\n",
      " 'Loss/total_loss': 0.47444147,\n",
      " 'learning_rate': 0.035385028}\n",
      "I1129 05:14:31.412195 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.24219017,\n",
      " 'Loss/localization_loss': 0.15951906,\n",
      " 'Loss/regularization_loss': 0.072732225,\n",
      " 'Loss/total_loss': 0.47444147,\n",
      " 'learning_rate': 0.035385028}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 162300 per-step time 2.765s\n",
      "I1129 05:19:07.880007 140606687830976 model_lib_v2.py:698] Step 162300 per-step time 2.765s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.19325575,\n",
      " 'Loss/localization_loss': 0.10497781,\n",
      " 'Loss/regularization_loss': 0.07271246,\n",
      " 'Loss/total_loss': 0.37094602,\n",
      " 'learning_rate': 0.035343073}\n",
      "I1129 05:19:07.880318 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.19325575,\n",
      " 'Loss/localization_loss': 0.10497781,\n",
      " 'Loss/regularization_loss': 0.07271246,\n",
      " 'Loss/total_loss': 0.37094602,\n",
      " 'learning_rate': 0.035343073}\n",
      "INFO:tensorflow:Step 162400 per-step time 2.776s\n",
      "I1129 05:23:45.472804 140606687830976 model_lib_v2.py:698] Step 162400 per-step time 2.776s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3479141,\n",
      " 'Loss/localization_loss': 0.20119104,\n",
      " 'Loss/regularization_loss': 0.07268276,\n",
      " 'Loss/total_loss': 0.6217879,\n",
      " 'learning_rate': 0.035301123}\n",
      "I1129 05:23:45.473113 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.3479141,\n",
      " 'Loss/localization_loss': 0.20119104,\n",
      " 'Loss/regularization_loss': 0.07268276,\n",
      " 'Loss/total_loss': 0.6217879,\n",
      " 'learning_rate': 0.035301123}\n",
      "INFO:tensorflow:Step 162500 per-step time 2.764s\n",
      "I1129 05:28:21.920511 140606687830976 model_lib_v2.py:698] Step 162500 per-step time 2.764s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2920518,\n",
      " 'Loss/localization_loss': 0.19561593,\n",
      " 'Loss/regularization_loss': 0.0726524,\n",
      " 'Loss/total_loss': 0.56032014,\n",
      " 'learning_rate': 0.03525918}\n",
      "I1129 05:28:21.920822 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.2920518,\n",
      " 'Loss/localization_loss': 0.19561593,\n",
      " 'Loss/regularization_loss': 0.0726524,\n",
      " 'Loss/total_loss': 0.56032014,\n",
      " 'learning_rate': 0.03525918}\n",
      "INFO:tensorflow:Step 162600 per-step time 2.777s\n",
      "I1129 05:32:59.630277 140606687830976 model_lib_v2.py:698] Step 162600 per-step time 2.777s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.30522603,\n",
      " 'Loss/localization_loss': 0.16164172,\n",
      " 'Loss/regularization_loss': 0.07262697,\n",
      " 'Loss/total_loss': 0.53949475,\n",
      " 'learning_rate': 0.035217237}\n",
      "I1129 05:32:59.630602 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.30522603,\n",
      " 'Loss/localization_loss': 0.16164172,\n",
      " 'Loss/regularization_loss': 0.07262697,\n",
      " 'Loss/total_loss': 0.53949475,\n",
      " 'learning_rate': 0.035217237}\n",
      "INFO:tensorflow:Step 162700 per-step time 2.778s\n",
      "I1129 05:37:37.458662 140606687830976 model_lib_v2.py:698] Step 162700 per-step time 2.778s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16714516,\n",
      " 'Loss/localization_loss': 0.09469692,\n",
      " 'Loss/regularization_loss': 0.072588995,\n",
      " 'Loss/total_loss': 0.33443108,\n",
      " 'learning_rate': 0.035175305}\n",
      "I1129 05:37:37.458973 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.16714516,\n",
      " 'Loss/localization_loss': 0.09469692,\n",
      " 'Loss/regularization_loss': 0.072588995,\n",
      " 'Loss/total_loss': 0.33443108,\n",
      " 'learning_rate': 0.035175305}\n",
      "INFO:tensorflow:Step 162800 per-step time 2.776s\n",
      "I1129 05:42:15.084270 140606687830976 model_lib_v2.py:698] Step 162800 per-step time 2.776s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.23549968,\n",
      " 'Loss/localization_loss': 0.13223793,\n",
      " 'Loss/regularization_loss': 0.0725549,\n",
      " 'Loss/total_loss': 0.44029248,\n",
      " 'learning_rate': 0.035133377}\n",
      "I1129 05:42:15.084578 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.23549968,\n",
      " 'Loss/localization_loss': 0.13223793,\n",
      " 'Loss/regularization_loss': 0.0725549,\n",
      " 'Loss/total_loss': 0.44029248,\n",
      " 'learning_rate': 0.035133377}\n",
      "INFO:tensorflow:Step 162900 per-step time 2.778s\n",
      "I1129 05:46:52.885632 140606687830976 model_lib_v2.py:698] Step 162900 per-step time 2.778s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.146806,\n",
      " 'Loss/localization_loss': 0.08061293,\n",
      " 'Loss/regularization_loss': 0.07252482,\n",
      " 'Loss/total_loss': 0.29994375,\n",
      " 'learning_rate': 0.035091452}\n",
      "I1129 05:46:52.885936 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.146806,\n",
      " 'Loss/localization_loss': 0.08061293,\n",
      " 'Loss/regularization_loss': 0.07252482,\n",
      " 'Loss/total_loss': 0.29994375,\n",
      " 'learning_rate': 0.035091452}\n",
      "INFO:tensorflow:Step 163000 per-step time 2.780s\n",
      "I1129 05:51:30.853196 140606687830976 model_lib_v2.py:698] Step 163000 per-step time 2.780s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.24057123,\n",
      " 'Loss/localization_loss': 0.16063926,\n",
      " 'Loss/regularization_loss': 0.07249154,\n",
      " 'Loss/total_loss': 0.47370204,\n",
      " 'learning_rate': 0.035049535}\n",
      "I1129 05:51:30.853514 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.24057123,\n",
      " 'Loss/localization_loss': 0.16063926,\n",
      " 'Loss/regularization_loss': 0.07249154,\n",
      " 'Loss/total_loss': 0.47370204,\n",
      " 'learning_rate': 0.035049535}\n",
      "INFO:tensorflow:Step 163100 per-step time 2.778s\n",
      "I1129 05:56:08.685485 140606687830976 model_lib_v2.py:698] Step 163100 per-step time 2.778s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.23847984,\n",
      " 'Loss/localization_loss': 0.16016348,\n",
      " 'Loss/regularization_loss': 0.072458416,\n",
      " 'Loss/total_loss': 0.4711017,\n",
      " 'learning_rate': 0.035007622}\n",
      "I1129 05:56:08.685819 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.23847984,\n",
      " 'Loss/localization_loss': 0.16016348,\n",
      " 'Loss/regularization_loss': 0.072458416,\n",
      " 'Loss/total_loss': 0.4711017,\n",
      " 'learning_rate': 0.035007622}\n",
      "INFO:tensorflow:Step 163200 per-step time 2.775s\n",
      "I1129 06:00:46.207579 140606687830976 model_lib_v2.py:698] Step 163200 per-step time 2.775s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2987406,\n",
      " 'Loss/localization_loss': 0.19665946,\n",
      " 'Loss/regularization_loss': 0.07242573,\n",
      " 'Loss/total_loss': 0.5678258,\n",
      " 'learning_rate': 0.034965716}\n",
      "I1129 06:00:46.207916 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.2987406,\n",
      " 'Loss/localization_loss': 0.19665946,\n",
      " 'Loss/regularization_loss': 0.07242573,\n",
      " 'Loss/total_loss': 0.5678258,\n",
      " 'learning_rate': 0.034965716}\n",
      "INFO:tensorflow:Step 163300 per-step time 2.777s\n",
      "I1129 06:05:23.938579 140606687830976 model_lib_v2.py:698] Step 163300 per-step time 2.777s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.26999444,\n",
      " 'Loss/localization_loss': 0.08603181,\n",
      " 'Loss/regularization_loss': 0.07239313,\n",
      " 'Loss/total_loss': 0.42841935,\n",
      " 'learning_rate': 0.034923814}\n",
      "I1129 06:05:23.938908 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.26999444,\n",
      " 'Loss/localization_loss': 0.08603181,\n",
      " 'Loss/regularization_loss': 0.07239313,\n",
      " 'Loss/total_loss': 0.42841935,\n",
      " 'learning_rate': 0.034923814}\n",
      "INFO:tensorflow:Step 163400 per-step time 2.780s\n",
      "I1129 06:10:01.951238 140606687830976 model_lib_v2.py:698] Step 163400 per-step time 2.780s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15222402,\n",
      " 'Loss/localization_loss': 0.046411596,\n",
      " 'Loss/regularization_loss': 0.07235888,\n",
      " 'Loss/total_loss': 0.27099448,\n",
      " 'learning_rate': 0.034881916}\n",
      "I1129 06:10:01.951551 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.15222402,\n",
      " 'Loss/localization_loss': 0.046411596,\n",
      " 'Loss/regularization_loss': 0.07235888,\n",
      " 'Loss/total_loss': 0.27099448,\n",
      " 'learning_rate': 0.034881916}\n",
      "INFO:tensorflow:Step 163500 per-step time 2.781s\n",
      "I1129 06:14:40.085553 140606687830976 model_lib_v2.py:698] Step 163500 per-step time 2.781s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.28639945,\n",
      " 'Loss/localization_loss': 0.11947547,\n",
      " 'Loss/regularization_loss': 0.0723175,\n",
      " 'Loss/total_loss': 0.47819245,\n",
      " 'learning_rate': 0.03484003}\n",
      "I1129 06:14:40.085872 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.28639945,\n",
      " 'Loss/localization_loss': 0.11947547,\n",
      " 'Loss/regularization_loss': 0.0723175,\n",
      " 'Loss/total_loss': 0.47819245,\n",
      " 'learning_rate': 0.03484003}\n",
      "INFO:tensorflow:Step 163600 per-step time 2.773s\n",
      "I1129 06:19:17.401494 140606687830976 model_lib_v2.py:698] Step 163600 per-step time 2.773s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.18742733,\n",
      " 'Loss/localization_loss': 0.05310678,\n",
      " 'Loss/regularization_loss': 0.07227112,\n",
      " 'Loss/total_loss': 0.31280524,\n",
      " 'learning_rate': 0.034798145}\n",
      "I1129 06:19:17.401803 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.18742733,\n",
      " 'Loss/localization_loss': 0.05310678,\n",
      " 'Loss/regularization_loss': 0.07227112,\n",
      " 'Loss/total_loss': 0.31280524,\n",
      " 'learning_rate': 0.034798145}\n",
      "INFO:tensorflow:Step 163700 per-step time 2.774s\n",
      "I1129 06:23:54.847270 140606687830976 model_lib_v2.py:698] Step 163700 per-step time 2.774s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.18270591,\n",
      " 'Loss/localization_loss': 0.064179376,\n",
      " 'Loss/regularization_loss': 0.072223306,\n",
      " 'Loss/total_loss': 0.3191086,\n",
      " 'learning_rate': 0.034756266}\n",
      "I1129 06:23:54.847582 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.18270591,\n",
      " 'Loss/localization_loss': 0.064179376,\n",
      " 'Loss/regularization_loss': 0.072223306,\n",
      " 'Loss/total_loss': 0.3191086,\n",
      " 'learning_rate': 0.034756266}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 163800 per-step time 2.782s\n",
      "I1129 06:28:33.038210 140606687830976 model_lib_v2.py:698] Step 163800 per-step time 2.782s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16398855,\n",
      " 'Loss/localization_loss': 0.036555804,\n",
      " 'Loss/regularization_loss': 0.07216673,\n",
      " 'Loss/total_loss': 0.27271107,\n",
      " 'learning_rate': 0.034714393}\n",
      "I1129 06:28:33.038523 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.16398855,\n",
      " 'Loss/localization_loss': 0.036555804,\n",
      " 'Loss/regularization_loss': 0.07216673,\n",
      " 'Loss/total_loss': 0.27271107,\n",
      " 'learning_rate': 0.034714393}\n",
      "INFO:tensorflow:Step 163900 per-step time 2.768s\n",
      "I1129 06:33:09.868819 140606687830976 model_lib_v2.py:698] Step 163900 per-step time 2.768s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16508768,\n",
      " 'Loss/localization_loss': 0.051326565,\n",
      " 'Loss/regularization_loss': 0.07211439,\n",
      " 'Loss/total_loss': 0.28852865,\n",
      " 'learning_rate': 0.03467253}\n",
      "I1129 06:33:09.869160 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.16508768,\n",
      " 'Loss/localization_loss': 0.051326565,\n",
      " 'Loss/regularization_loss': 0.07211439,\n",
      " 'Loss/total_loss': 0.28852865,\n",
      " 'learning_rate': 0.03467253}\n",
      "INFO:tensorflow:Step 164000 per-step time 2.774s\n",
      "I1129 06:37:47.272341 140606687830976 model_lib_v2.py:698] Step 164000 per-step time 2.774s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13198449,\n",
      " 'Loss/localization_loss': 0.05625735,\n",
      " 'Loss/regularization_loss': 0.07205932,\n",
      " 'Loss/total_loss': 0.26030114,\n",
      " 'learning_rate': 0.03463067}\n",
      "I1129 06:37:47.272653 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.13198449,\n",
      " 'Loss/localization_loss': 0.05625735,\n",
      " 'Loss/regularization_loss': 0.07205932,\n",
      " 'Loss/total_loss': 0.26030114,\n",
      " 'learning_rate': 0.03463067}\n",
      "INFO:tensorflow:Step 164100 per-step time 2.786s\n",
      "I1129 06:42:25.917191 140606687830976 model_lib_v2.py:698] Step 164100 per-step time 2.786s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15257934,\n",
      " 'Loss/localization_loss': 0.03959129,\n",
      " 'Loss/regularization_loss': 0.07200255,\n",
      " 'Loss/total_loss': 0.26417318,\n",
      " 'learning_rate': 0.034588814}\n",
      "I1129 06:42:25.917519 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.15257934,\n",
      " 'Loss/localization_loss': 0.03959129,\n",
      " 'Loss/regularization_loss': 0.07200255,\n",
      " 'Loss/total_loss': 0.26417318,\n",
      " 'learning_rate': 0.034588814}\n",
      "INFO:tensorflow:Step 164200 per-step time 2.769s\n",
      "I1129 06:47:02.844672 140606687830976 model_lib_v2.py:698] Step 164200 per-step time 2.769s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.097772315,\n",
      " 'Loss/localization_loss': 0.025207514,\n",
      " 'Loss/regularization_loss': 0.07194602,\n",
      " 'Loss/total_loss': 0.19492584,\n",
      " 'learning_rate': 0.034546968}\n",
      "I1129 06:47:02.844995 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.097772315,\n",
      " 'Loss/localization_loss': 0.025207514,\n",
      " 'Loss/regularization_loss': 0.07194602,\n",
      " 'Loss/total_loss': 0.19492584,\n",
      " 'learning_rate': 0.034546968}\n",
      "INFO:tensorflow:Step 164300 per-step time 2.772s\n",
      "I1129 06:51:40.072072 140606687830976 model_lib_v2.py:698] Step 164300 per-step time 2.772s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15073818,\n",
      " 'Loss/localization_loss': 0.061255436,\n",
      " 'Loss/regularization_loss': 0.0718856,\n",
      " 'Loss/total_loss': 0.28387922,\n",
      " 'learning_rate': 0.034505118}\n",
      "I1129 06:51:40.072456 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.15073818,\n",
      " 'Loss/localization_loss': 0.061255436,\n",
      " 'Loss/regularization_loss': 0.0718856,\n",
      " 'Loss/total_loss': 0.28387922,\n",
      " 'learning_rate': 0.034505118}\n",
      "INFO:tensorflow:Step 164400 per-step time 2.774s\n",
      "I1129 06:56:17.518180 140606687830976 model_lib_v2.py:698] Step 164400 per-step time 2.774s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13132387,\n",
      " 'Loss/localization_loss': 0.040072776,\n",
      " 'Loss/regularization_loss': 0.07182917,\n",
      " 'Loss/total_loss': 0.24322581,\n",
      " 'learning_rate': 0.034463286}\n",
      "I1129 06:56:17.518502 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.13132387,\n",
      " 'Loss/localization_loss': 0.040072776,\n",
      " 'Loss/regularization_loss': 0.07182917,\n",
      " 'Loss/total_loss': 0.24322581,\n",
      " 'learning_rate': 0.034463286}\n",
      "INFO:tensorflow:Step 164500 per-step time 2.778s\n",
      "I1129 07:00:55.302005 140606687830976 model_lib_v2.py:698] Step 164500 per-step time 2.778s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13816275,\n",
      " 'Loss/localization_loss': 0.04402942,\n",
      " 'Loss/regularization_loss': 0.071777984,\n",
      " 'Loss/total_loss': 0.25397015,\n",
      " 'learning_rate': 0.03442145}\n",
      "I1129 07:00:55.302324 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.13816275,\n",
      " 'Loss/localization_loss': 0.04402942,\n",
      " 'Loss/regularization_loss': 0.071777984,\n",
      " 'Loss/total_loss': 0.25397015,\n",
      " 'learning_rate': 0.03442145}\n",
      "INFO:tensorflow:Step 164600 per-step time 2.777s\n",
      "I1129 07:05:33.033867 140606687830976 model_lib_v2.py:698] Step 164600 per-step time 2.777s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.19064987,\n",
      " 'Loss/localization_loss': 0.052262545,\n",
      " 'Loss/regularization_loss': 0.07175021,\n",
      " 'Loss/total_loss': 0.31466264,\n",
      " 'learning_rate': 0.034379628}\n",
      "I1129 07:05:33.034176 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.19064987,\n",
      " 'Loss/localization_loss': 0.052262545,\n",
      " 'Loss/regularization_loss': 0.07175021,\n",
      " 'Loss/total_loss': 0.31466264,\n",
      " 'learning_rate': 0.034379628}\n",
      "INFO:tensorflow:Step 164700 per-step time 2.777s\n",
      "I1129 07:10:10.747498 140606687830976 model_lib_v2.py:698] Step 164700 per-step time 2.777s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.28524148,\n",
      " 'Loss/localization_loss': 0.11125964,\n",
      " 'Loss/regularization_loss': 0.07172357,\n",
      " 'Loss/total_loss': 0.4682247,\n",
      " 'learning_rate': 0.034337815}\n",
      "I1129 07:10:10.747803 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.28524148,\n",
      " 'Loss/localization_loss': 0.11125964,\n",
      " 'Loss/regularization_loss': 0.07172357,\n",
      " 'Loss/total_loss': 0.4682247,\n",
      " 'learning_rate': 0.034337815}\n",
      "INFO:tensorflow:Step 164800 per-step time 2.780s\n",
      "I1129 07:14:48.723172 140606687830976 model_lib_v2.py:698] Step 164800 per-step time 2.780s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.23351239,\n",
      " 'Loss/localization_loss': 0.13860603,\n",
      " 'Loss/regularization_loss': 0.07169697,\n",
      " 'Loss/total_loss': 0.44381535,\n",
      " 'learning_rate': 0.034296002}\n",
      "I1129 07:14:48.723497 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.23351239,\n",
      " 'Loss/localization_loss': 0.13860603,\n",
      " 'Loss/regularization_loss': 0.07169697,\n",
      " 'Loss/total_loss': 0.44381535,\n",
      " 'learning_rate': 0.034296002}\n",
      "INFO:tensorflow:Step 164900 per-step time 2.778s\n",
      "I1129 07:19:26.476591 140606687830976 model_lib_v2.py:698] Step 164900 per-step time 2.778s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2692092,\n",
      " 'Loss/localization_loss': 0.10793676,\n",
      " 'Loss/regularization_loss': 0.071671344,\n",
      " 'Loss/total_loss': 0.4488173,\n",
      " 'learning_rate': 0.034254193}\n",
      "I1129 07:19:26.476912 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.2692092,\n",
      " 'Loss/localization_loss': 0.10793676,\n",
      " 'Loss/regularization_loss': 0.071671344,\n",
      " 'Loss/total_loss': 0.4488173,\n",
      " 'learning_rate': 0.034254193}\n",
      "INFO:tensorflow:Step 165000 per-step time 2.779s\n",
      "I1129 07:24:04.387233 140606687830976 model_lib_v2.py:698] Step 165000 per-step time 2.779s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.27285808,\n",
      " 'Loss/localization_loss': 0.1560258,\n",
      " 'Loss/regularization_loss': 0.07165028,\n",
      " 'Loss/total_loss': 0.5005342,\n",
      " 'learning_rate': 0.0342124}\n",
      "I1129 07:24:04.387543 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.27285808,\n",
      " 'Loss/localization_loss': 0.1560258,\n",
      " 'Loss/regularization_loss': 0.07165028,\n",
      " 'Loss/total_loss': 0.5005342,\n",
      " 'learning_rate': 0.0342124}\n",
      "INFO:tensorflow:Step 165100 per-step time 2.786s\n",
      "I1129 07:28:43.018088 140606687830976 model_lib_v2.py:698] Step 165100 per-step time 2.786s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.26236317,\n",
      " 'Loss/localization_loss': 0.16212694,\n",
      " 'Loss/regularization_loss': 0.07161695,\n",
      " 'Loss/total_loss': 0.49610704,\n",
      " 'learning_rate': 0.03417061}\n",
      "I1129 07:28:43.018795 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.26236317,\n",
      " 'Loss/localization_loss': 0.16212694,\n",
      " 'Loss/regularization_loss': 0.07161695,\n",
      " 'Loss/total_loss': 0.49610704,\n",
      " 'learning_rate': 0.03417061}\n",
      "INFO:tensorflow:Step 165200 per-step time 2.779s\n",
      "I1129 07:33:20.883763 140606687830976 model_lib_v2.py:698] Step 165200 per-step time 2.779s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1992834,\n",
      " 'Loss/localization_loss': 0.08514349,\n",
      " 'Loss/regularization_loss': 0.07159844,\n",
      " 'Loss/total_loss': 0.35602534,\n",
      " 'learning_rate': 0.034128822}\n",
      "I1129 07:33:20.884098 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.1992834,\n",
      " 'Loss/localization_loss': 0.08514349,\n",
      " 'Loss/regularization_loss': 0.07159844,\n",
      " 'Loss/total_loss': 0.35602534,\n",
      " 'learning_rate': 0.034128822}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 165300 per-step time 2.779s\n",
      "I1129 07:37:58.812122 140606687830976 model_lib_v2.py:698] Step 165300 per-step time 2.779s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14633602,\n",
      " 'Loss/localization_loss': 0.074198,\n",
      " 'Loss/regularization_loss': 0.07157013,\n",
      " 'Loss/total_loss': 0.29210415,\n",
      " 'learning_rate': 0.034087036}\n",
      "I1129 07:37:58.812450 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.14633602,\n",
      " 'Loss/localization_loss': 0.074198,\n",
      " 'Loss/regularization_loss': 0.07157013,\n",
      " 'Loss/total_loss': 0.29210415,\n",
      " 'learning_rate': 0.034087036}\n",
      "INFO:tensorflow:Step 165400 per-step time 2.779s\n",
      "I1129 07:42:36.741398 140606687830976 model_lib_v2.py:698] Step 165400 per-step time 2.779s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17582251,\n",
      " 'Loss/localization_loss': 0.08690763,\n",
      " 'Loss/regularization_loss': 0.07154377,\n",
      " 'Loss/total_loss': 0.3342739,\n",
      " 'learning_rate': 0.034045268}\n",
      "I1129 07:42:36.741709 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.17582251,\n",
      " 'Loss/localization_loss': 0.08690763,\n",
      " 'Loss/regularization_loss': 0.07154377,\n",
      " 'Loss/total_loss': 0.3342739,\n",
      " 'learning_rate': 0.034045268}\n",
      "INFO:tensorflow:Step 165500 per-step time 2.774s\n",
      "I1129 07:47:14.161396 140606687830976 model_lib_v2.py:698] Step 165500 per-step time 2.774s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.18974246,\n",
      " 'Loss/localization_loss': 0.09754986,\n",
      " 'Loss/regularization_loss': 0.071514964,\n",
      " 'Loss/total_loss': 0.35880727,\n",
      " 'learning_rate': 0.0340035}\n",
      "I1129 07:47:14.161730 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.18974246,\n",
      " 'Loss/localization_loss': 0.09754986,\n",
      " 'Loss/regularization_loss': 0.071514964,\n",
      " 'Loss/total_loss': 0.35880727,\n",
      " 'learning_rate': 0.0340035}\n",
      "INFO:tensorflow:Step 165600 per-step time 2.779s\n",
      "I1129 07:51:52.041419 140606687830976 model_lib_v2.py:698] Step 165600 per-step time 2.779s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.30781737,\n",
      " 'Loss/localization_loss': 0.22997008,\n",
      " 'Loss/regularization_loss': 0.07149717,\n",
      " 'Loss/total_loss': 0.60928464,\n",
      " 'learning_rate': 0.033961743}\n",
      "I1129 07:51:52.041727 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.30781737,\n",
      " 'Loss/localization_loss': 0.22997008,\n",
      " 'Loss/regularization_loss': 0.07149717,\n",
      " 'Loss/total_loss': 0.60928464,\n",
      " 'learning_rate': 0.033961743}\n",
      "INFO:tensorflow:Step 165700 per-step time 2.782s\n",
      "I1129 07:56:30.205186 140606687830976 model_lib_v2.py:698] Step 165700 per-step time 2.782s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.220351,\n",
      " 'Loss/localization_loss': 0.15537342,\n",
      " 'Loss/regularization_loss': 0.071473196,\n",
      " 'Loss/total_loss': 0.44719762,\n",
      " 'learning_rate': 0.033919986}\n",
      "I1129 07:56:30.205513 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.220351,\n",
      " 'Loss/localization_loss': 0.15537342,\n",
      " 'Loss/regularization_loss': 0.071473196,\n",
      " 'Loss/total_loss': 0.44719762,\n",
      " 'learning_rate': 0.033919986}\n",
      "INFO:tensorflow:Step 165800 per-step time 2.780s\n",
      "I1129 08:01:08.202041 140606687830976 model_lib_v2.py:698] Step 165800 per-step time 2.780s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17421655,\n",
      " 'Loss/localization_loss': 0.072176315,\n",
      " 'Loss/regularization_loss': 0.071456224,\n",
      " 'Loss/total_loss': 0.3178491,\n",
      " 'learning_rate': 0.033878244}\n",
      "I1129 08:01:08.202362 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.17421655,\n",
      " 'Loss/localization_loss': 0.072176315,\n",
      " 'Loss/regularization_loss': 0.071456224,\n",
      " 'Loss/total_loss': 0.3178491,\n",
      " 'learning_rate': 0.033878244}\n",
      "INFO:tensorflow:Step 165900 per-step time 2.778s\n",
      "I1129 08:05:45.982618 140606687830976 model_lib_v2.py:698] Step 165900 per-step time 2.778s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.22482023,\n",
      " 'Loss/localization_loss': 0.10083624,\n",
      " 'Loss/regularization_loss': 0.071471125,\n",
      " 'Loss/total_loss': 0.3971276,\n",
      " 'learning_rate': 0.033836506}\n",
      "I1129 08:05:45.982944 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.22482023,\n",
      " 'Loss/localization_loss': 0.10083624,\n",
      " 'Loss/regularization_loss': 0.071471125,\n",
      " 'Loss/total_loss': 0.3971276,\n",
      " 'learning_rate': 0.033836506}\n",
      "INFO:tensorflow:Step 166000 per-step time 2.788s\n",
      "I1129 08:10:24.808297 140606687830976 model_lib_v2.py:698] Step 166000 per-step time 2.788s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2852806,\n",
      " 'Loss/localization_loss': 0.17918508,\n",
      " 'Loss/regularization_loss': 0.071494125,\n",
      " 'Loss/total_loss': 0.5359598,\n",
      " 'learning_rate': 0.033794776}\n",
      "I1129 08:10:24.808632 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.2852806,\n",
      " 'Loss/localization_loss': 0.17918508,\n",
      " 'Loss/regularization_loss': 0.071494125,\n",
      " 'Loss/total_loss': 0.5359598,\n",
      " 'learning_rate': 0.033794776}\n",
      "INFO:tensorflow:Step 166100 per-step time 2.791s\n",
      "I1129 08:15:03.894766 140606687830976 model_lib_v2.py:698] Step 166100 per-step time 2.791s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.24502337,\n",
      " 'Loss/localization_loss': 0.10287157,\n",
      " 'Loss/regularization_loss': 0.07152053,\n",
      " 'Loss/total_loss': 0.41941547,\n",
      " 'learning_rate': 0.03375305}\n",
      "I1129 08:15:03.895087 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.24502337,\n",
      " 'Loss/localization_loss': 0.10287157,\n",
      " 'Loss/regularization_loss': 0.07152053,\n",
      " 'Loss/total_loss': 0.41941547,\n",
      " 'learning_rate': 0.03375305}\n",
      "INFO:tensorflow:Step 166200 per-step time 2.776s\n",
      "I1129 08:19:41.539814 140606687830976 model_lib_v2.py:698] Step 166200 per-step time 2.776s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.18234798,\n",
      " 'Loss/localization_loss': 0.063638724,\n",
      " 'Loss/regularization_loss': 0.07154072,\n",
      " 'Loss/total_loss': 0.3175274,\n",
      " 'learning_rate': 0.033711333}\n",
      "I1129 08:19:41.540123 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.18234798,\n",
      " 'Loss/localization_loss': 0.063638724,\n",
      " 'Loss/regularization_loss': 0.07154072,\n",
      " 'Loss/total_loss': 0.3175274,\n",
      " 'learning_rate': 0.033711333}\n",
      "INFO:tensorflow:Step 166300 per-step time 2.782s\n",
      "I1129 08:24:19.703062 140606687830976 model_lib_v2.py:698] Step 166300 per-step time 2.782s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.31535718,\n",
      " 'Loss/localization_loss': 0.1123091,\n",
      " 'Loss/regularization_loss': 0.07153319,\n",
      " 'Loss/total_loss': 0.49919945,\n",
      " 'learning_rate': 0.033669617}\n",
      "I1129 08:24:19.703374 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.31535718,\n",
      " 'Loss/localization_loss': 0.1123091,\n",
      " 'Loss/regularization_loss': 0.07153319,\n",
      " 'Loss/total_loss': 0.49919945,\n",
      " 'learning_rate': 0.033669617}\n",
      "INFO:tensorflow:Step 166400 per-step time 2.776s\n",
      "I1129 08:28:57.310609 140606687830976 model_lib_v2.py:698] Step 166400 per-step time 2.776s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.20421737,\n",
      " 'Loss/localization_loss': 0.076693125,\n",
      " 'Loss/regularization_loss': 0.071539566,\n",
      " 'Loss/total_loss': 0.35245007,\n",
      " 'learning_rate': 0.033627916}\n",
      "I1129 08:28:57.310925 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.20421737,\n",
      " 'Loss/localization_loss': 0.076693125,\n",
      " 'Loss/regularization_loss': 0.071539566,\n",
      " 'Loss/total_loss': 0.35245007,\n",
      " 'learning_rate': 0.033627916}\n",
      "INFO:tensorflow:Step 166500 per-step time 2.767s\n",
      "I1129 08:33:34.015942 140606687830976 model_lib_v2.py:698] Step 166500 per-step time 2.767s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.30424786,\n",
      " 'Loss/localization_loss': 0.16946182,\n",
      " 'Loss/regularization_loss': 0.07152728,\n",
      " 'Loss/total_loss': 0.54523695,\n",
      " 'learning_rate': 0.033586215}\n",
      "I1129 08:33:34.016269 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.30424786,\n",
      " 'Loss/localization_loss': 0.16946182,\n",
      " 'Loss/regularization_loss': 0.07152728,\n",
      " 'Loss/total_loss': 0.54523695,\n",
      " 'learning_rate': 0.033586215}\n",
      "INFO:tensorflow:Step 166600 per-step time 2.766s\n",
      "I1129 08:38:10.591811 140606687830976 model_lib_v2.py:698] Step 166600 per-step time 2.766s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.18312149,\n",
      " 'Loss/localization_loss': 0.08119085,\n",
      " 'Loss/regularization_loss': 0.07152006,\n",
      " 'Loss/total_loss': 0.3358324,\n",
      " 'learning_rate': 0.03354453}\n",
      "I1129 08:38:10.592098 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.18312149,\n",
      " 'Loss/localization_loss': 0.08119085,\n",
      " 'Loss/regularization_loss': 0.07152006,\n",
      " 'Loss/total_loss': 0.3358324,\n",
      " 'learning_rate': 0.03354453}\n",
      "INFO:tensorflow:Step 166700 per-step time 2.763s\n",
      "I1129 08:42:46.875357 140606687830976 model_lib_v2.py:698] Step 166700 per-step time 2.763s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.21210733,\n",
      " 'Loss/localization_loss': 0.11935203,\n",
      " 'Loss/regularization_loss': 0.071526565,\n",
      " 'Loss/total_loss': 0.40298593,\n",
      " 'learning_rate': 0.033502843}\n",
      "I1129 08:42:46.875687 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.21210733,\n",
      " 'Loss/localization_loss': 0.11935203,\n",
      " 'Loss/regularization_loss': 0.071526565,\n",
      " 'Loss/total_loss': 0.40298593,\n",
      " 'learning_rate': 0.033502843}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 166800 per-step time 2.766s\n",
      "I1129 08:47:23.431342 140606687830976 model_lib_v2.py:698] Step 166800 per-step time 2.766s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.4529175,\n",
      " 'Loss/localization_loss': 0.13846931,\n",
      " 'Loss/regularization_loss': 0.07154852,\n",
      " 'Loss/total_loss': 0.6629354,\n",
      " 'learning_rate': 0.033461172}\n",
      "I1129 08:47:23.431670 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.4529175,\n",
      " 'Loss/localization_loss': 0.13846931,\n",
      " 'Loss/regularization_loss': 0.07154852,\n",
      " 'Loss/total_loss': 0.6629354,\n",
      " 'learning_rate': 0.033461172}\n",
      "INFO:tensorflow:Step 166900 per-step time 2.764s\n",
      "I1129 08:51:59.861817 140606687830976 model_lib_v2.py:698] Step 166900 per-step time 2.764s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2569399,\n",
      " 'Loss/localization_loss': 0.1365116,\n",
      " 'Loss/regularization_loss': 0.0715723,\n",
      " 'Loss/total_loss': 0.4650238,\n",
      " 'learning_rate': 0.0334195}\n",
      "I1129 08:51:59.862128 140606687830976 model_lib_v2.py:701] {'Loss/classification_loss': 0.2569399,\n",
      " 'Loss/localization_loss': 0.1365116,\n",
      " 'Loss/regularization_loss': 0.0715723,\n",
      " 'Loss/total_loss': 0.4650238,\n",
      " 'learning_rate': 0.0334195}\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python -u /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_file} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --sample_1_of_n_eval_examples=1 \\\n",
    "    --num_eval_steps={num_eval_steps} 2>&1 | sed -e \"/nan/q9\";echo $? > exitcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.2: Fire the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "9KNv1N_hUibE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W1129 08:56:28.223756 139691689034688 model_lib_v2.py:1081] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "I1129 08:56:28.223995 139691689034688 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I1129 08:56:28.224082 139691689034688 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I1129 08:56:28.224174 139691689034688 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W1129 08:56:28.224303 139691689034688 model_lib_v2.py:1099] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "2021-11-29 08:56:28.227993: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-29 08:56:28.750110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10801 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0001:00:00.0, compute capability: 3.7\n",
      "I1129 08:56:28.886931 139691689034688 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I1129 08:56:28.887129 139691689034688 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
      "I1129 08:56:28.887207 139691689034688 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 3\n",
      "I1129 08:56:28.891371 139691689034688 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I1129 08:56:28.915820 139691689034688 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I1129 08:56:28.915940 139691689034688 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I1129 08:56:28.978422 139691689034688 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I1129 08:56:28.978565 139691689034688 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I1129 08:56:29.296962 139691689034688 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I1129 08:56:29.297149 139691689034688 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I1129 08:56:29.457158 139691689034688 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I1129 08:56:29.457337 139691689034688 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I1129 08:56:29.700558 139691689034688 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I1129 08:56:29.700713 139691689034688 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I1129 08:56:29.943549 139691689034688 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I1129 08:56:29.943727 139691689034688 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I1129 08:56:30.268457 139691689034688 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I1129 08:56:30.268630 139691689034688 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I1129 08:56:30.346666 139691689034688 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I1129 08:56:30.377492 139691689034688 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/pictures/output_tfrecords_v2/valid/merged_logos.tfrecord']\n",
      "I1129 08:56:30.426878 139691689034688 dataset_builder.py:163] Reading unweighted datasets: ['/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/pictures/output_tfrecords_v2/valid/merged_logos.tfrecord']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/pictures/output_tfrecords_v2/valid/merged_logos.tfrecord']\n",
      "I1129 08:56:30.427061 139691689034688 dataset_builder.py:80] Reading record datasets for input file: ['/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/pictures/output_tfrecords_v2/valid/merged_logos.tfrecord']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I1129 08:56:30.427155 139691689034688 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W1129 08:56:30.427246 139691689034688 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /anaconda/envs/py38_default/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W1129 08:56:30.428613 139691689034688 deprecation.py:339] From /anaconda/envs/py38_default/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /anaconda/envs/py38_default/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W1129 08:56:30.452058 139691689034688 deprecation.py:339] From /anaconda/envs/py38_default/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/py38_default/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W1129 08:56:34.725991 139691689034688 deprecation.py:339] From /anaconda/envs/py38_default/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /anaconda/envs/py38_default/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1129 08:56:35.965649 139691689034688 deprecation.py:339] From /anaconda/envs/py38_default/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Waiting for new checkpoint at /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/TENSOR_RESULTS/efficientdet-d0/config_7\n",
      "I1129 08:56:38.763954 139691689034688 checkpoint_utils.py:140] Waiting for new checkpoint at /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/TENSOR_RESULTS/efficientdet-d0/config_7\n",
      "INFO:tensorflow:Found new checkpoint at /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/TENSOR_RESULTS/efficientdet-d0/config_7/ckpt-167\n",
      "I1129 08:56:38.764873 139691689034688 checkpoint_utils.py:149] Found new checkpoint at /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/TENSOR_RESULTS/efficientdet-d0/config_7/ckpt-167\n",
      "/anaconda/envs/py38_default/lib/python3.8/site-packages/keras/backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "2021-11-29 08:56:40.823098: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-29 08:58:39.000623: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8202\n",
      "WARNING:tensorflow:From /anaconda/envs/py38_default/lib/python3.8/site-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1129 08:58:41.097517 139691689034688 deprecation.py:339] From /anaconda/envs/py38_default/lib/python3.8/site-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Finished eval step 0\n",
      "I1129 08:58:41.226597 139691689034688 model_lib_v2.py:958] Finished eval step 0\n",
      "WARNING:tensorflow:From /anaconda/envs/py38_default/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W1129 08:58:41.352173 139691689034688 deprecation.py:339] From /anaconda/envs/py38_default/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "INFO:tensorflow:Finished eval step 100\n",
      "I1129 09:00:39.076288 139691689034688 model_lib_v2.py:958] Finished eval step 100\n",
      "INFO:tensorflow:Finished eval step 200\n",
      "I1129 09:02:12.659011 139691689034688 model_lib_v2.py:958] Finished eval step 200\n",
      "INFO:tensorflow:Finished eval step 300\n",
      "I1129 09:03:46.464163 139691689034688 model_lib_v2.py:958] Finished eval step 300\n",
      "INFO:tensorflow:Finished eval step 400\n",
      "I1129 09:05:19.810811 139691689034688 model_lib_v2.py:958] Finished eval step 400\n",
      "INFO:tensorflow:Performing evaluation on 7312 images.\n",
      "I1129 09:06:11.302204 139691689034688 coco_evaluation.py:293] Performing evaluation on 7312 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I1129 09:06:11.320362 139691689034688 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.40s)\n",
      "I1129 09:06:11.720402 139691689034688 coco_tools.py:138] DONE (t=0.40s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=35.57s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=17.42s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.640\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.883\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.757\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.694\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.703\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.609\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.705\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.716\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.492\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.765\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.762\n",
      "INFO:tensorflow:Eval metrics at step 166000\n",
      "I1129 09:07:06.253372 139691689034688 model_lib_v2.py:1007] Eval metrics at step 166000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.640028\n",
      "I1129 09:07:06.257812 139691689034688 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP: 0.640028\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.882939\n",
      "I1129 09:07:06.258990 139691689034688 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.882939\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.756726\n",
      "I1129 09:07:06.260102 139691689034688 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.756726\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.367386\n",
      "I1129 09:07:06.261226 139691689034688 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (small): 0.367386\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.693868\n",
      "I1129 09:07:06.262348 139691689034688 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (medium): 0.693868\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.703000\n",
      "I1129 09:07:06.263623 139691689034688 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (large): 0.703000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.609487\n",
      "I1129 09:07:06.264742 139691689034688 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@1: 0.609487\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.705277\n",
      "I1129 09:07:06.265855 139691689034688 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@10: 0.705277\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.715593\n",
      "I1129 09:07:06.266978 139691689034688 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100: 0.715593\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.491970\n",
      "I1129 09:07:06.268092 139691689034688 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (small): 0.491970\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.764702\n",
      "I1129 09:07:06.269345 139691689034688 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.764702\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.762292\n",
      "I1129 09:07:06.270483 139691689034688 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (large): 0.762292\n",
      "INFO:tensorflow:\t+ Loss/localization_loss: 0.074495\n",
      "I1129 09:07:06.271372 139691689034688 model_lib_v2.py:1010] \t+ Loss/localization_loss: 0.074495\n",
      "INFO:tensorflow:\t+ Loss/classification_loss: 0.200088\n",
      "I1129 09:07:06.272272 139691689034688 model_lib_v2.py:1010] \t+ Loss/classification_loss: 0.200088\n",
      "INFO:tensorflow:\t+ Loss/regularization_loss: 0.071495\n",
      "I1129 09:07:06.273170 139691689034688 model_lib_v2.py:1010] \t+ Loss/regularization_loss: 0.071495\n",
      "INFO:tensorflow:\t+ Loss/total_loss: 0.346078\n",
      "I1129 09:07:06.274062 139691689034688 model_lib_v2.py:1010] \t+ Loss/total_loss: 0.346078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Waiting for new checkpoint at /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/TENSOR_RESULTS/efficientdet-d0/config_7\n",
      "I1129 09:07:08.605666 139691689034688 checkpoint_utils.py:140] Waiting for new checkpoint at /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/TENSOR_RESULTS/efficientdet-d0/config_7\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research/object_detection/model_main_tf2.py\", line 115, in <module>\n",
      "    tf.compat.v1.app.run()\n",
      "  File \"/anaconda/envs/py38_default/lib/python3.8/site-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/anaconda/envs/py38_default/lib/python3.8/site-packages/absl/app.py\", line 303, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/anaconda/envs/py38_default/lib/python3.8/site-packages/absl/app.py\", line 251, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research/object_detection/model_main_tf2.py\", line 82, in main\n",
      "    model_lib_v2.eval_continuously(\n",
      "  File \"/anaconda/envs/py38_default/lib/python3.8/site-packages/object_detection/model_lib_v2.py\", line 1128, in eval_continuously\n",
      "    for latest_checkpoint in tf.train.checkpoints_iterator(\n",
      "  File \"/anaconda/envs/py38_default/lib/python3.8/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 198, in checkpoints_iterator\n",
      "    new_checkpoint_path = wait_for_new_checkpoint(\n",
      "  File \"/anaconda/envs/py38_default/lib/python3.8/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 147, in wait_for_new_checkpoint\n",
      "    time.sleep(seconds_to_sleep)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#run model evaluation to obtain performance metrics\n",
    "\n",
    "!python /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_file} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --checkpoint_dir={model_dir} \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_training_directory = os.path.join(model_dir, \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Vk2146Ogil3"
   },
   "source": [
    "# Step 4: Exporting a Trained Inference Graph\n",
    "We can now export the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vqaZ4v-vIuDl",
    "outputId": "050f887a-7594-4359-d084-e0ac99865e75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint                    ckpt-165.data-00000-of-00001\r\n",
      "ckpt-161.data-00000-of-00001  ckpt-165.index\r\n",
      "ckpt-161.index                ckpt-166.data-00000-of-00001\r\n",
      "ckpt-162.data-00000-of-00001  ckpt-166.index\r\n",
      "ckpt-162.index                ckpt-167.data-00000-of-00001\r\n",
      "ckpt-163.data-00000-of-00001  ckpt-167.index\r\n",
      "ckpt-163.index                \u001b[0m\u001b[01;34meval\u001b[0m/\r\n",
      "ckpt-164.data-00000-of-00001  \u001b[01;34mtrain\u001b[0m/\r\n",
      "ckpt-164.index\r\n"
     ]
    }
   ],
   "source": [
    "#see where our model saved weights\n",
    "%ls $model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training\n"
     ]
    }
   ],
   "source": [
    "%cd /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/TENSOR_RESULTS/efficientdet-d0/config_7'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YnSEZIzl4M10",
    "outputId": "22c6bedb-294a-414a-93bf-b14a76ff481c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:The directory FINE_TUNED_MODEL is already present, files will be stored there\n",
      "INFO:root:The folder model_run_directory WAS ALREADY PRESENT and is set to be: \n",
      " /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/FINE_TUNED_MODEL/efficientdet-d0\n",
      "INFO:root:The folder output_directory is set to be: \n",
      " /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/FINE_TUNED_MODEL/efficientdet-d0/config_7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/TENSOR_RESULTS/efficientdet-d0/config_7\n"
     ]
    }
   ],
   "source": [
    "#run conversion script\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "fine_tuned_directory = '/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/FINE_TUNED_MODEL'\n",
    "\n",
    "if \"FINE_TUNED_MODEL\" not in os.listdir(os.getcwd()):\n",
    "    os.mkdir(fine_tuned_directory)\n",
    "    logging.info(\"Creating the directory TENSOR_RESULTS because it did not exist\") \n",
    "else:\n",
    "    logging.info(\"The directory FINE_TUNED_MODEL is already present, files will be stored there\")\n",
    "    \n",
    "model_fine_tuned_directory = os.path.join(fine_tuned_directory, chosen_model)\n",
    "\n",
    "if chosen_model not in os.listdir(fine_tuned_directory):\n",
    "    try:\n",
    "        os.mkdir(model_fine_tuned_directory)\n",
    "        logging.info(f\"The folder model_fine_tuned_directory is set to be: \\n {model_fine_tuned_directory}\")\n",
    "    except FileExistsError:\n",
    "        logging.info(f\"FILEEXISTSERROR: The folder model_fine_tuned_directory is set to be: \\n {model_fine_tuned_directory}\")\n",
    "else:\n",
    "    logging.info(f\"The folder model_run_directory WAS ALREADY PRESENT and is set to be: \\n {model_fine_tuned_directory}\")\n",
    "\n",
    "output_directory = os.path.join(model_fine_tuned_directory, config_subfolder.split(\"/\")[-1])\n",
    "\n",
    "if config_subfolder.split(\"/\")[-1] not in os.listdir(model_fine_tuned_directory):\n",
    "    try:\n",
    "        os.mkdir(output_directory)\n",
    "        logging.info(f\"The folder output_directory is set to be: \\n {output_directory}\")\n",
    "    except FileExistsError:\n",
    "        logging.info(f\"FILEEXISTSERROR: The folder output_directory WAS ALREADY PRESENT and is set to be: \\n {output_directory}\")\n",
    "\n",
    "# Place the model weights you would like to export here\n",
    "last_model_path = model_dir\n",
    "print(last_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 09:14:50.955399: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-29 09:14:51.484762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10801 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0001:00:00.0, compute capability: 3.7\n",
      "I1129 09:14:51.620954 140607865910208 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I1129 09:14:51.621170 140607865910208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
      "I1129 09:14:51.621247 140607865910208 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 3\n",
      "I1129 09:14:51.625047 140607865910208 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I1129 09:14:51.648497 140607865910208 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I1129 09:14:51.648599 140607865910208 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I1129 09:14:51.712693 140607865910208 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I1129 09:14:51.712801 140607865910208 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I1129 09:14:51.870785 140607865910208 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I1129 09:14:51.870916 140607865910208 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I1129 09:14:52.029706 140607865910208 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I1129 09:14:52.029828 140607865910208 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I1129 09:14:52.270061 140607865910208 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I1129 09:14:52.270218 140607865910208 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I1129 09:14:52.512046 140607865910208 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I1129 09:14:52.512188 140607865910208 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I1129 09:14:52.830822 140607865910208 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I1129 09:14:52.830986 140607865910208 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I1129 09:14:52.906919 140607865910208 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I1129 09:14:52.938920 140607865910208 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "WARNING:tensorflow:From /anaconda/envs/py38_default/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W1129 09:14:54.921763 140607865910208 deprecation.py:611] From /anaconda/envs/py38_default/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fe14c7d56a0>, because it is not built.\n",
      "W1129 09:15:16.364543 140607865910208 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fe14c7d56a0>, because it is not built.\n",
      "2021-11-29 09:15:46.036811: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "W1129 09:16:28.860403 140607865910208 save.py:249] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 795). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/FINE_TUNED_MODEL/efficientdet-d0/config_7/saved_model/assets\n",
      "I1129 09:16:40.860825 140607865910208 builder_impl.py:780] Assets written to: /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/FINE_TUNED_MODEL/efficientdet-d0/config_7/saved_model/assets\n",
      "INFO:tensorflow:Writing pipeline config file to /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/FINE_TUNED_MODEL/efficientdet-d0/config_7/pipeline.config\n",
      "I1129 09:16:43.325657 140607865910208 config_util.py:253] Writing pipeline config file to /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/FINE_TUNED_MODEL/efficientdet-d0/config_7/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "!python /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research/object_detection/exporter_main_v2.py \\\n",
    "    --trained_checkpoint_dir {last_model_path} \\\n",
    "    --output_directory {output_directory} \\\n",
    "    --pipeline_config_path {pipeline_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_directory = os.path.join(output_directory, \"saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TsE_uVjlsz3u",
    "outputId": "eb23557c-9456-43c3-a577-ea4b7ef1522b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34massets\u001b[0m/  saved_model.pb  \u001b[01;34mvariables\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls $saved_model_directory"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Roboflow-TensorFlow2-Object-Detection.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "40a8aae49d8ead891f177a9aa92f4d86d5628cb1b4814a86ede39a8e1ef554b8"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
