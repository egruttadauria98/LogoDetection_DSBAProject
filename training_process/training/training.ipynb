{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fF8ysCfYKgTP"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "We will take the following steps to implement Efficientdet-D0 on our custom data:\n",
    "* Install TensorFlow2 Object Detection Dependencies\n",
    "* Write Custom TensorFlow2 Object Detection Training Configuation\n",
    "* Train Custom TensorFlow2 Object Detection Model\n",
    "* Export Custom TensorFlow2 Object Detection Weights\n",
    "\n",
    "The inference made with our model can be found in the inference folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7EOtpvlLeS0"
   },
   "source": [
    "# Step 1: Install TensorFlow2 Object Detection Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "Requirement already satisfied: gitpython in /anaconda/envs/py38_default/lib/python3.8/site-packages (3.1.24)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from gitpython) (4.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from gitpython) (3.7.4.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/anaconda/envs/py38_default/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gitpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypWGYdPlLRUN",
    "outputId": "64d4d196-f81a-4e85-bc6e-a2650e185855"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from git import Repo\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "models_folder = os.path.join(os.getcwd(), \"models\")\n",
    "\n",
    "# Clone the tensorflow models repository if it doesn't already exist in this folder\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "    while \"models\" in pathlib.Path.cwd().parts:\n",
    "        os.chdir('..')\n",
    "\n",
    "    logging.info(\"The models have already been uploaded. Change working directory to the models folder.\")\n",
    "\n",
    "elif not pathlib.Path('models').exists():\n",
    "    os.mkdir(\"./models\")\n",
    "    repo = Repo.clone_from(\n",
    "        'http://RebSolcia:Clementinabookie18121998!@github.com/tensorflow/models.git',\n",
    "        models_folder,\n",
    "        depth=1,\n",
    "        branch='master',\n",
    "    )\n",
    "\n",
    "    logging.info(\"The models have now been loaded from the tensorflow/models.git repo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.1: PyCoco library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycoco_folder = os.path.join(os.getcwd(), \"pycoco\")\n",
    "\n",
    "# Clone the pycoco repository if it doesn't exist. It is needed to avoid clashes with the TF2API\n",
    "if \"pycoco\" in pathlib.Path.cwd().parts:\n",
    "    while \"pycoco\" in pathlib.Path.cwd().parts:\n",
    "        os.chdir('..')\n",
    "\n",
    "    logging.info(\"The models have already been uploaded. Change working directory to the models folder.\")\n",
    "\n",
    "elif not pathlib.Path('pycoco').exists():\n",
    "    os.mkdir(\"./pycoco\")\n",
    "    repo = Repo.clone_from(\n",
    "        'http://RebSolcia:Clementinabookie18121998!@github.com/cocodataset/cocoapi.git',\n",
    "        pycoco_folder, \n",
    "        branch=\"master\"\n",
    "    )\n",
    "\n",
    "    logging.info(\"The models have now been loaded from the coco repo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps are needed in order to avoid having problems with Pycoco.\n",
    "\n",
    "1. Clone the official repository\n",
    "2. Navigate to the PythonAPI folder and open the setup.py file\n",
    "3. Edit line 12 to be extra_compile_args=[]. The rationale here is to remove the Clang specific arguments, which don’t work on MVCC.\n",
    "\n",
    "4. Run the following line\n",
    "\n",
    "\n",
    "This final command will build and install the package within your current environment, ready to go. To test if the installation succeeded, fire up Python and import it as: import pycocotools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/pycoco/PythonAPI\n",
      "running build_ext\n",
      "skipping 'pycocotools/_mask.c' Cython extension (up-to-date)\n",
      "copying build/lib.linux-x86_64-3.8/pycocotools/_mask.cpython-38-x86_64-linux-gnu.so -> pycocotools\n"
     ]
    }
   ],
   "source": [
    "%cd /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/pycoco/PythonAPI\n",
    "!python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.2: Changes to the Models folder\n",
    "\n",
    "1. Navigate to “./research/object_detection/packages/tf2/” and edit the setup.py file. From the REQUIRED_PACKAGES list, delete the pycocotools reference (line 20). This change will prevent the installation process from trying to reinstall pycocotools from pip, which would fail and abort the whole process.\n",
    "2. Copy this setup.py file to the “./research” folder, replacing the setup.py that was already there.\n",
    "3. Once you're done, run the following line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6QPmVBSlLTzM",
    "outputId": "32e07c91-e6fc-432b-b41a-2885a86f5985",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "Processing /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "Requirement already satisfied: avro-python3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (1.9.2.1)\n",
      "Requirement already satisfied: apache-beam in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (2.33.0)\n",
      "Requirement already satisfied: pillow in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (8.3.1)\n",
      "Requirement already satisfied: lxml in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (4.6.3)\n",
      "Requirement already satisfied: matplotlib in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (3.3.4)\n",
      "Requirement already satisfied: Cython in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (0.29.23)\n",
      "Requirement already satisfied: contextlib2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (21.6.0)\n",
      "Requirement already satisfied: tf-slim in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: six in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (1.15.0)\n",
      "Requirement already satisfied: lvis in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (0.5.3)\n",
      "Requirement already satisfied: scipy in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (1.4.1)\n",
      "Requirement already satisfied: pandas in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (1.2.5)\n",
      "Requirement already satisfied: tf-models-official>=2.5.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: tensorflow_io in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (0.21.0)\n",
      "Requirement already satisfied: keras==2.6.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: sacrebleu in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.0.0)\n",
      "Requirement already satisfied: sentencepiece in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.96)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.8.0)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.28.0)\n",
      "Requirement already satisfied: gin-config in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: tensorflow>=2.5.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.6.1)\n",
      "Requirement already satisfied: tensorflow-addons in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.14.0)\n",
      "Requirement already satisfied: tensorflow-text>=2.5.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: opencv-python-headless in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.5.4.58)\n",
      "Requirement already satisfied: seqeval in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n",
      "Requirement already satisfied: tensorflow-datasets in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.4)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: pycocotools in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.0.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.1)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
      "Requirement already satisfied: oauth2client in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.19.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.32.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=1.21.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.2.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (52.0.0.post20210125)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.53.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.25.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.7.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil in /anaconda/envs/py38_default/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.1)\n",
      "Requirement already satisfied: python-slugify in /anaconda/envs/py38_default/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.26.6)\n",
      "Requirement already satisfied: certifi in /anaconda/envs/py38_default/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.5.30)\n",
      "Requirement already satisfied: tqdm in /anaconda/envs/py38_default/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.61.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytz>=2017.3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pandas->object-detection==0.1) (2021.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
      "Collecting h5py~=3.1.0\n",
      "  Using cached h5py-3.1.0-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
      "Collecting numpy>=1.15.4\n",
      "  Using cached numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.2.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n",
      "Requirement already satisfied: clang~=5.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (5.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.4.3)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.41.1)\n",
      "Requirement already satisfied: wheel~=0.35 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.36.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n",
      "Requirement already satisfied: fastavro<2,>=0.21.4 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from apache-beam->object-detection==0.1) (1.4.6)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from apache-beam->object-detection==0.1) (1.7)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from apache-beam->object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: future<1.0.0,>=0.18.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from apache-beam->object-detection==0.1) (0.18.2)\n",
      "Requirement already satisfied: pyarrow<5.0.0,>=0.15.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from apache-beam->object-detection==0.1) (4.0.1)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from apache-beam->object-detection==0.1) (3.12.1)\n",
      "Requirement already satisfied: orjson<4.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from apache-beam->object-detection==0.1) (3.6.4)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: docopt in /anaconda/envs/py38_default/lib/python3.8/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from lvis->object-detection==0.1) (4.5.3.56)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from lvis->object-detection==0.1) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from lvis->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
      "Requirement already satisfied: portalocker in /anaconda/envs/py38_default/lib/python3.8/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2.3.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
      "Requirement already satisfied: regex in /anaconda/envs/py38_default/lib/python3.8/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2021.7.6)\n",
      "Requirement already satisfied: colorama in /anaconda/envs/py38_default/lib/python3.8/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.4.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn>=0.21.3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (2.2.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.13.0)\n",
      "Requirement already satisfied: importlib-resources in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.3.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.2.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.4.0)\n",
      "Requirement already satisfied: promise in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from importlib-resources->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.21.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from tensorflow_io->object-detection==0.1) (0.21.0)\n",
      "Building wheels for collected packages: object-detection\n",
      "  Building wheel for object-detection (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1679343 sha256=1b5e3f8b92dcd941c211464759d37ca68a41226b59cb5b0653353cb51b251ed9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-bhu658bj/wheels/a4/27/31/b41a2f9b118ebb35237b34adc3f408b0c60bd7f122d0a7eb79\n",
      "Successfully built object-detection\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "Installing collected packages: numpy, h5py, object-detection\n",
      "  Attempting uninstall: numpy\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "    Found existing installation: numpy 1.21.4\n",
      "    Uninstalling numpy-1.21.4:\n",
      "      Successfully uninstalled numpy-1.21.4\n",
      "  Attempting uninstall: h5py\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "    Found existing installation: h5py 2.9.0\n",
      "    Uninstalling h5py-2.9.0:\n",
      "      Successfully uninstalled h5py-2.9.0\n",
      "  Attempting uninstall: object-detection\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "    Found existing installation: object-detection 0.1\n",
      "    Uninstalling object-detection-0.1:\n",
      "      Successfully uninstalled object-detection-0.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fbprophet 0.7.1 requires cmdstanpy==0.9.5, which is not installed.\n",
      "fbprophet 0.7.1 requires setuptools-git>=1.2, which is not installed.\n",
      "tensorflow-gpu 2.5.0 requires grpcio~=1.34.0, but you have grpcio 1.41.1 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires tensorflow-estimator<2.6.0,>=2.5.0rc0, but you have tensorflow-estimator 2.2.0 which is incompatible.\n",
      "networkx 2.6.1 requires scipy!=1.6.1,>=1.5, but you have scipy 1.4.1 which is incompatible.\u001b[0m\n",
      "Successfully installed h5py-3.1.0 numpy-1.19.5 object-detection-0.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/anaconda/envs/py38_default/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%cd /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "%cp /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research/object_detection/packages/tf2/setup.py .\n",
    "!pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.3: Uninstall and install h5py\n",
    "\n",
    "Make sure to uninstall h5py and re-install it in the 2.9 version, because otherwise there might be problems with the training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "Found existing installation: h5py 3.1.0\n",
      "Uninstalling h5py-3.1.0:\n",
      "  Successfully uninstalled h5py-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall h5py -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "Collecting h5py==2.9\n",
      "  Using cached h5py-2.9.0-cp38-cp38-manylinux1_x86_64.whl (2.8 MB)\n",
      "Requirement already satisfied: numpy>=1.7 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from h5py==2.9) (1.19.5)\n",
      "Requirement already satisfied: six in /anaconda/envs/py38_default/lib/python3.8/site-packages (from h5py==2.9) (1.15.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "Installing collected packages: h5py\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.6.1 requires h5py~=3.1.0, but you have h5py 2.9.0 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires grpcio~=1.34.0, but you have grpcio 1.41.1 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires h5py~=3.1.0, but you have h5py 2.9.0 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires tensorflow-estimator<2.6.0,>=2.5.0rc0, but you have tensorflow-estimator 2.2.0 which is incompatible.\u001b[0m\n",
      "Successfully installed h5py-2.9.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -5py (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/anaconda/envs/py38_default/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/anaconda/envs/py38_default/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py==2.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Prepare the model for training\n",
    "\n",
    "Once everything is installed, import all the libraries that are needed and launch a sample training to check that everything works smoothly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wHfsJ5nWLWh9"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import io\n",
    "import imageio\n",
    "import glob\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, Javascript\n",
    "from IPython.display import Image as IPyImage\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from models.research.object_detection.utils import label_map_util\n",
    "from models.research.object_detection.utils import config_util\n",
    "from models.research.object_detection.utils import visualization_utils as viz_utils\n",
    "from models.research.object_detection.builders import model_builder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a pip freeze to see whether tensorflow-gpu is installed, and run the test to see everything works smoothly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wh_HPMOqWH9z",
    "outputId": "31063c4e-d8f1-484e-c325-005553c763eb"
   },
   "outputs": [],
   "source": [
    "#run model builder test\n",
    "!python /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research/object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1: Import the data\n",
    "\n",
    "Change current directory to be sure everything works smoothly. This process of directory change will take place often to ensure code compatibility when constructing paths. \n",
    "\n",
    "Eventually, also remember to change the names of the files so that they are compatible with yours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Set the pictures directory to be the one containing your train and validation folders of interest\n",
    "picture_files_directory = \"/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/pictures/\"\n",
    "\n",
    "# Set the names of the folders to respect the right path to the TFRecords\n",
    "test_record_fname = os.path.join(picture_files_directory,\"output_tfrecords_v2/valid/merged_logos.tfrecord\")\n",
    "train_record_fname = os.path.join(picture_files_directory,\"output_tfrecords_v2/train/merged_logos.tfrecord\")\n",
    "label_map_pbtxt_fname = os.path.join(picture_files_directory, \"output_tfrecords_v2/train/logos_label_map.pbtxt\")\n",
    "\n",
    "print(train_record_fname,label_map_pbtxt_fname, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2MAcgJ53STW"
   },
   "source": [
    "## Step 2.2: Configure Custom TensorFlow2 Object Detection Training Configuration\n",
    "\n",
    "To be able to use different models, we populated the file ModelSetting.py with the models we thought would be good to train. \n",
    "\n",
    "From the ModelZoo, it is possible to pick the pre_trained_checkpoints (extension tar.gz) and the model_name (that must be the same as the one given to the pre_trained_checkpoints):\n",
    "https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
    "\n",
    "By entering the *raw* version of the ModelZoo page on GitHub, it is possible to pick the the names of the tar.gz.\n",
    "\n",
    "To find instead the configurations: \n",
    "https://github.com/tensorflow/models/tree/master/research/object_detection/configs/tf2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install prettyprinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gN0EUEa3e5Un"
   },
   "outputs": [],
   "source": [
    "# Step 1: import model settings\n",
    "# For each model, this file returns important info to actually use the model\n",
    "\n",
    "from ModelSettings import Model_Setting\n",
    "from prettyprinter import pprint\n",
    "\n",
    "MODELS_CONFIG = Model_Setting()\n",
    "\n",
    "pprint(MODELS_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: chose the model and extract relevant info\n",
    "\n",
    "chosen_model = 'efficientdet-d0'\n",
    "\n",
    "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
    "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
    "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
    "batch_size = MODELS_CONFIG[chosen_model]['batch_size'] #if you can fit a large batch in memory, it may speed up your training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The more steps, the longer the training. \n",
    "# Increase if your loss function is still decreasing and validation metrics are increasing. \n",
    "num_steps = 500000\n",
    "\n",
    "#Perform evaluation after so many steps\n",
    "num_eval_steps = 3000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXTRA: Deploy folder structure\n",
    "\n",
    "Inside the \"research\" folder, we will create a \"deploy\" folder in which we will dump all the data related to the model used and its specific configuration. <br>\n",
    "For this reason, the structure of the deploy folder is as follows:\n",
    "\n",
    "Deploy:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Model A:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Config 1<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Config 2<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;...<br>\n",
    "\n",
    "This means that, once we choose a model:\n",
    "1. if there is no folder within \"deploy\" with the model name, then create it and create the the Config 1 folder within the model folder.\n",
    "2. if there is a folder with the name of the model, we need to check if the configurtion of the current model is the same as the one in the folder. If not, create a new Config folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If it does not exist already, create the 'deploy' folder inside training/models/research\n",
    "\n",
    "main_deploy_folder = '/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research/deploy'\n",
    "\n",
    "if \"deploy\" not in os.listdir(os.getcwd()):\n",
    "    os.mkdir(main_deploy_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_configs_for_model(chosen_model):\n",
    "    \n",
    "    # This is a dict with config folder names as keys and values of the config as values\n",
    "    folder_to_values = dict()\n",
    "    \n",
    "    model_path = os.path.join(main_deploy_folder, chosen_model)\n",
    "    \n",
    "    for config_folder in os.listdir(model_path):\n",
    "        if not config_folder == \".ipynb_checkpoints\":\n",
    "            print(config_folder)\n",
    "            config_path = os.path.join(model_path, config_folder)\n",
    "\n",
    "            config_file = os.path.join(config_path,r'pipeline_file.config')\n",
    "            config_values = list()\n",
    "\n",
    "            with open(config_file) as f:\n",
    "                file = f.read()\n",
    "\n",
    "                # Extract all values except the path of the data\n",
    "                # This mean that if we train the same config of a model on a different version of the data, this will overwrite the results\n",
    "                # TODO: add path of the data as well?\n",
    "                # TODO: add fine tune check points?\n",
    "                config_values.append(re.search('batch_size: [0-9]+', file).group()[len('batch_size: '):])\n",
    "                config_values.append(re.search('num_steps: [0-9]+', file).group()[len('num_steps: '):])\n",
    "                config_values.append(re.search('num_classes: [0-9]+', file).group()[len('num_classes: '):])\n",
    "\n",
    "            folder_to_values[config_folder] = config_values\n",
    "        \n",
    "    return folder_to_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_ki9jOqxn7V"
   },
   "outputs": [],
   "source": [
    "def get_num_classes(pbtxt_fname):\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_config = [\n",
    "    str(batch_size),\n",
    "    str(num_steps),\n",
    "    str(num_classes)\n",
    "]\n",
    "\n",
    "current_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the model has never been used, then create folder for the model and for the current config, the latter inside the former\n",
    "\n",
    "def update_repo_structure(chosen_model):\n",
    "    \n",
    "    model_folder = main_deploy_folder + '/' + chosen_model\n",
    "    \n",
    "    # TODO: it has to be folder, not file\n",
    "    if chosen_model not in os.listdir(main_deploy_folder):\n",
    "        # Case 1: model never used\n",
    "        os.mkdir(model_folder)\n",
    "\n",
    "        config_folder = model_folder + '/config_1'\n",
    "        os.mkdir(config_folder)\n",
    "\n",
    "        print('case1')\n",
    "        print(config_folder)\n",
    "\n",
    "    else:\n",
    "        # Case 2: model already used\n",
    "\n",
    "        list_configs = extract_configs_for_model(chosen_model)\n",
    "        print(list_configs)\n",
    "\n",
    "        if current_config in list(list_configs.values()):\n",
    "            \n",
    "            # Case A: Specifics configs per model already used\n",
    "            for key in list(list_configs.keys()):\n",
    "                if list_configs[key] == current_config:\n",
    "                    config_folder = key\n",
    "                    print('case a')\n",
    "                    print(config_folder)\n",
    "\n",
    "        else:\n",
    "            # Case B: new configs\n",
    "            config_folder = model_folder + f'/config_{len(list_configs)+1}'\n",
    "            os.mkdir(config_folder)\n",
    "            print('case b')\n",
    "            print(config_folder)\n",
    "            \n",
    "    return config_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the proper config folder to use in the next cells \n",
    "\n",
    "config_subfolder = update_repo_structure(chosen_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_folder = os.path.join(os.path.join(main_deploy_folder, chosen_model),config_subfolder)\n",
    "config_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kG4TmJUVrYQ7",
    "outputId": "a7a90aca-9383-4007-b6fb-02729ee02e37"
   },
   "outputs": [],
   "source": [
    "# Step 3.a: using info from step 2, download the weights of the model\n",
    "\n",
    "import tarfile\n",
    "import requests\n",
    "\n",
    "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
    "\n",
    "file_to_be_opened = os.path.join(config_folder, pretrained_checkpoint)\n",
    "\n",
    "# Unzip the tar.gz\n",
    "response = requests.get(download_tar, stream=True)\n",
    "if response.status_code == 200:\n",
    "    with open(file_to_be_opened, 'wb') as f:\n",
    "        f.write(response.raw.read())\n",
    "\n",
    "tar = tarfile.open(file_to_be_opened)\n",
    "tar.extractall(path=config_folder)\n",
    "tar.close()\n",
    "\n",
    "# TODO: once the tar has been extracted, delete the tar file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-nqYZtdtsgG",
    "outputId": "48f68a17-6ec5-4436-8ff0-a4d549186709"
   },
   "outputs": [],
   "source": [
    "# Step 3.b: using info from step 2, download base training configuration file\n",
    "\n",
    "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
    "\n",
    "abrir = os.path.join(config_folder, base_pipeline_file)\n",
    "\n",
    "response = requests.get(download_config, stream=True)\n",
    "if response.status_code == 200:\n",
    "    with open(abrir, 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_fname = os.path.join(config_folder, base_pipeline_file)\n",
    "print(pipeline_fname)\n",
    "\n",
    "fine_tune_checkpoint = os.path.join(config_folder, model_name,\"checkpoint\", \"ckpt-0\")\n",
    "print(fine_tune_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5eA5ht3_yukT",
    "outputId": "fe9716f3-ed98-4a17-f80c-83660b05bdfe"
   },
   "outputs": [],
   "source": [
    "# Write custom configuration file by slotting our dataset, model checkpoint, and training parameters into \n",
    "# the base pipeline file\n",
    "\n",
    "import re\n",
    "\n",
    "print('writing custom configuration file')\n",
    "\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()\n",
    "\n",
    "with open(os.path.join(config_folder, r'pipeline_file.config'), 'w') as f:\n",
    "    \n",
    "    # fine_tune_checkpoint\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               f'fine_tune_checkpoint: \"{fine_tune_checkpoint}\"', s)\n",
    "    \n",
    "    logging.info(\"Written fine tune checkpoint\")\n",
    "    \n",
    "    # tfrecord files train and test.\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', f'input_path: \"{train_record_fname}\"', s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', f'input_path: \"{test_record_fname}\"', s)\n",
    "    \n",
    "    logging.info(\"Written input path\")\n",
    "\n",
    "    # label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', f'label_map_path: \"{label_map_pbtxt_fname}\"', s)\n",
    "    \n",
    "    logging.info(\"Written label map\")\n",
    "\n",
    "    # Set training batch_size.\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               f'batch_size: {batch_size}', s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               f'num_steps: {num_steps}', s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               f'num_classes: {num_classes}', s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('learning_rate_base: [a-z.0-9-]+',\n",
    "               f'learning_rate_base: 0.08', s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('warmup_learning_rate: [a-z.0-9-]+',\n",
    "               f'warmup_learning_rate: 0.001', s)\n",
    "    \n",
    "    #fine-tune checkpoint type\n",
    "    s = re.sub(\n",
    "        'fine_tune_checkpoint_type: \"classification\"', \n",
    "        'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
    "    \n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_file = os.path.join(config_folder, 'pipeline_file.config')\n",
    "pipeline_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GMlaN3rs3zLe"
   },
   "outputs": [],
   "source": [
    "# Create the TENSOR_RESULTS directory, to store our models\n",
    "\n",
    "if \"TENSOR_RESULTS\" not in os.listdir(os.getcwd()):\n",
    "    os.mkdir(os.path.join(os.getcwd(),\"TENSOR_RESULTS\"))\n",
    "    logging.info(\"Creating the directory TENSOR_RESULTS because it did not exist\") \n",
    "else:\n",
    "    logging.info(\"The directory TENSOR_RESULTS is already present, files will be stored there\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_results_directory = '/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/TENSOR_RESULTS'\n",
    "\n",
    "model_run_directory = os.path.join('/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/TENSOR_RESULTS',\n",
    "                                  chosen_model)\n",
    "\n",
    "# Similarly to what we did for the configurations, we generate model results subdirectories inside TENSOR_RESULTS to then\n",
    "# be able to restore the already-trained checkpoints\n",
    "\n",
    "if chosen_model not in os.listdir(tensor_results_directory):\n",
    "    try:\n",
    "        os.mkdir(os.path.join(tensor_results_directory, chosen_model))\n",
    "        logging.info(f\"The folder model_run_directory is set to be: \\n {model_run_directory}\")\n",
    "    except FileExistsError:\n",
    "        logging.info(f\"FILEEXISTSERROR: The folder model_run_directory is set to be: \\n {model_run_directory}\")\n",
    "else:\n",
    "    logging.info(f\"The folder model_run_directory WAS ALREADY PRESENT and is set to be: \\n {model_run_directory}\")\n",
    "\n",
    "model_dir = os.path.join(model_run_directory, config_subfolder.split(\"/\")[-1])\n",
    "\n",
    "if config_subfolder.split(\"/\")[-1] not in os.listdir(model_run_directory):\n",
    "    try:\n",
    "        os.mkdir(os.path.join(model_run_directory, config_subfolder))\n",
    "        logging.info(f\"The folder model_dir is set to be: \\n {model_dir}\")\n",
    "    except FileExistsError:\n",
    "        logging.info(f\"FILEEXISTSERROR: The folder model_dir WAS ALREADY PRESENT and is set to be: \\n {model_dir}\")\n",
    "else:\n",
    "    logging.info(f\"The folder model_dir WAS ALREADY PRESENT and is set to be: \\n {model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxPj_QV43qD5"
   },
   "source": [
    "# Step 3: Train Custom TF2 Object Detector\n",
    "\n",
    "With this information, we can start training the model:\n",
    "\n",
    "* pipeline_file: defined above in writing custom training configuration\n",
    "* model_dir: the location tensorboard logs and saved model checkpoints will save to\n",
    "* num_train_steps: how long to train for\n",
    "* num_eval_steps: perform eval on validation set after this many steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PIPELINE FILE: \" + str(pipeline_file), \n",
    "      \"MODEL DIRECTORY: \" + str(model_dir), \n",
    "      \"NUMBER OF STEPS: \" + str(num_steps), \n",
    "      \"NUMBER OF EVALUATION STEPS: \" + str(num_eval_steps), \n",
    "      sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU presence and regularize their usage\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.1: Fire the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQTfZChVzzpZ",
    "outputId": "48bf9506-ddd1-4de9-9629-d55602e1fea2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!python -u /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_file} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --sample_1_of_n_eval_examples=1 \\\n",
    "    --num_eval_steps={num_eval_steps} 2>&1 | sed -e \"/nan/q9\";echo $? > exitcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.2: Fire the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9KNv1N_hUibE"
   },
   "outputs": [],
   "source": [
    "#run model evaluation to obtain performance metrics\n",
    "\n",
    "!python /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_file} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --checkpoint_dir={model_dir} \\\n",
    "\n",
    "#Not yet implemented for EfficientDet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_training_directory = os.path.join(model_dir, \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Vk2146Ogil3"
   },
   "source": [
    "# Step 4: Exporting a Trained Inference Graph\n",
    "We can now export the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vqaZ4v-vIuDl",
    "outputId": "050f887a-7594-4359-d084-e0ac99865e75"
   },
   "outputs": [],
   "source": [
    "#see where our model saved weights\n",
    "%ls $model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YnSEZIzl4M10",
    "outputId": "22c6bedb-294a-414a-93bf-b14a76ff481c"
   },
   "outputs": [],
   "source": [
    "#run conversion script\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "fine_tuned_directory = '/home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/FINE_TUNED_MODEL'\n",
    "\n",
    "if \"FINE_TUNED_MODEL\" not in os.listdir(os.getcwd()):\n",
    "    os.mkdir(fine_tuned_directory)\n",
    "    logging.info(\"Creating the directory TENSOR_RESULTS because it did not exist\") \n",
    "else:\n",
    "    logging.info(\"The directory FINE_TUNED_MODEL is already present, files will be stored there\")\n",
    "    \n",
    "model_fine_tuned_directory = os.path.join(fine_tuned_directory, chosen_model)\n",
    "\n",
    "if chosen_model not in os.listdir(fine_tuned_directory):\n",
    "    try:\n",
    "        os.mkdir(model_fine_tuned_directory)\n",
    "        logging.info(f\"The folder model_fine_tuned_directory is set to be: \\n {model_fine_tuned_directory}\")\n",
    "    except FileExistsError:\n",
    "        logging.info(f\"FILEEXISTSERROR: The folder model_fine_tuned_directory is set to be: \\n {model_fine_tuned_directory}\")\n",
    "else:\n",
    "    logging.info(f\"The folder model_run_directory WAS ALREADY PRESENT and is set to be: \\n {model_fine_tuned_directory}\")\n",
    "\n",
    "output_directory = os.path.join(model_fine_tuned_directory, config_subfolder.split(\"/\")[-1])\n",
    "\n",
    "if config_subfolder.split(\"/\")[-1] not in os.listdir(model_fine_tuned_directory):\n",
    "    try:\n",
    "        os.mkdir(output_directory)\n",
    "        logging.info(f\"The folder output_directory is set to be: \\n {output_directory}\")\n",
    "    except FileExistsError:\n",
    "        logging.info(f\"FILEEXISTSERROR: The folder output_directory WAS ALREADY PRESENT and is set to be: \\n {output_directory}\")\n",
    "\n",
    "# Place the model weights you would like to export here\n",
    "last_model_path = model_dir\n",
    "print(last_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /home/labuser/LogoDet/LogoDetection_DSBAProject/training_process/training/models/research/object_detection/exporter_main_v2.py \\\n",
    "    --trained_checkpoint_dir {last_model_path} \\\n",
    "    --output_directory {output_directory} \\\n",
    "    --pipeline_config_path {pipeline_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_directory = os.path.join(output_directory, \"saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TsE_uVjlsz3u",
    "outputId": "eb23557c-9456-43c3-a577-ea4b7ef1522b"
   },
   "outputs": [],
   "source": [
    "%ls $saved_model_directory"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Roboflow-TensorFlow2-Object-Detection.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "40a8aae49d8ead891f177a9aa92f4d86d5628cb1b4814a86ede39a8e1ef554b8"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
