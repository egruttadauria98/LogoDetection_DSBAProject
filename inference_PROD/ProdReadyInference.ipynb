{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production-Ready Inference\n",
    "The production-ready inference Jupyter Notebook is meant to allow a user-friendly inference that can be run in local, without the need to struggle for understanding deeply what is going on under the hood of our model and trying to find a way out from our hierarchy!\n",
    "\n",
    "Before running this notebook, make sure that you have all of these things in place:\n",
    "1. You have inserted the images for which you want your annotations to be predicted inside the **INFERENCE_DIR** folder.\n",
    "2. You have added a file named **annotations.csv** to the **ANNOTATIONS&PREDICTIONS** folder, if you want your ground-truth annotations to be compared to the predictions made by our model.\n",
    "\n",
    "# SEE WHETHER TO ADD HERE THE CHECKPOINTS ALREADY!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import logging\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "  \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "  Puts image into numpy array to feed into tensorflow graph.\n",
    "  Note that by convention we put it into a numpy array with shape\n",
    "  (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "  Args:\n",
    "    path: the file path to the image\n",
    "\n",
    "  Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3)\n",
    "  \"\"\"\n",
    "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "  image = Image.open(BytesIO(img_data))\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is: c:/Users/rebec/Documents/GitHub/ObjectRecognition/LogoDetection_DSBAProject and the fine-tuned model is contained in c:/Users/rebec/Documents/GitHub/ObjectRecognition/LogoDetection_DSBAProject/inference_PROD/model_folder/FINE_TUNED_MODEL/bestmodel\n"
     ]
    }
   ],
   "source": [
    "model = \"model_folder\"\n",
    "config = \"bestmodel\"\n",
    "\n",
    "current_working_directory = \"/\".join(os.getcwd().split(\"\\\\\")[:-1])\n",
    "output_directory = f'{current_working_directory}/inference_PROD/{model}/FINE_TUNED_MODEL/{config}'\n",
    "\n",
    "print(f\"The current working directory is: {current_working_directory} and the fine-tuned model is contained in {output_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changes to the pipeline files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the inference over your images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('c:/Users/rebec/Documents/GitHub/ObjectRecognition/LogoDetection_DSBAProject/inference_PROD/model_folder/FINE_TUNED_MODEL/bestmodel/checkpoint/ckpt-0.index')]\n",
      "c:/Users/rebec/Documents/GitHub/ObjectRecognition/LogoDetection_DSBAProject/inference_PROD/model_folder/deploy/config_6/pipeline_file.config\n",
      "<object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x000002432C4CC280>\n",
      "[WindowsPath('c:/Users/rebec/Documents/GitHub/ObjectRecognition/LogoDetection_DSBAProject/inference_PROD/model_folder/FINE_TUNED_MODEL/bestmodel/checkpoint/ckpt-0.index')]\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "filenames = list(pathlib.Path(os.path.join(output_directory,\"checkpoint\")).glob('*.index'))\n",
    "filenames.sort()\n",
    "print(filenames)\n",
    "\n",
    "#recover our saved model\n",
    "pipeline_file = f\"{current_working_directory}/inference_PROD/{model}/deploy/config_6/pipeline_file.config\"\n",
    "print(pipeline_file)\n",
    "pipeline_config = pipeline_file\n",
    "\n",
    "#generally you want to put the last ckpt from training in here\n",
    "model_dir = str(filenames).replace('.index','')\n",
    "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
    "model_config = configs['model']\n",
    "#print(model_config)\n",
    "detection_model = model_builder.build(\n",
    "      model_config=model_config, is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(\n",
    "      model=detection_model)\n",
    "\n",
    "print(detection_model)\n",
    "print(filenames)\n",
    "ckpt.restore(os.path.join(str(filenames[-1]).replace('.index','')))\n",
    "\n",
    "\n",
    "def get_model_detection_function(model):\n",
    "  \"\"\"Get a tf.function for detection.\"\"\"\n",
    "\n",
    "  @tf.function\n",
    "  def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = model.preprocess(image)\n",
    "    prediction_dict = model.predict(image, shapes)\n",
    "    detections = model.postprocess(prediction_dict, shapes)\n",
    "    \n",
    "    \n",
    "    return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
    "\n",
    "  return detect_fn\n",
    "\n",
    "detect_fn = get_model_detection_function(detection_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Adidas': 1, 'AppleInc': 2, 'MercedesBenz': 3, 'NFL': 4, 'Nike': 5, 'Puma': 6, 'Starbucks': 7, 'TheNorthFace': 8, 'UnderArmour': 9}\n"
     ]
    }
   ],
   "source": [
    "#map labels for inference decoding\n",
    "label_map_path = f\"{current_working_directory}/inference_PROD/{model}/label_map/logos_label_map.pbtxt\"\n",
    "#label_map_path = configs['eval_input_config'].label_map_path\n",
    "label_map = label_map_util.load_labelmap(label_map_path)\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map,\n",
    "    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
    "    use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)\n",
    "\n",
    "print(label_map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run detector on test image\n",
    "#it takes a little longer on the first run and then runs at normal speed. \n",
    "\n",
    "import random\n",
    "\n",
    "TEST_IMAGE_PATHS = glob.glob(f'{current_working_directory}/inference_PROD/INFERENCE_DIR/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "import time\n",
    "\n",
    "def print_true_predicted(image):\n",
    "\n",
    "    if \"COMPARE\" not in os.listdir(os.getcwd()):\n",
    "        os.mkdir(os.path.join(os.getcwd(), \"COMPARE\"))\n",
    "\n",
    "    image_path = image\n",
    "    image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(\n",
    "        np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "    threshold = 0.2\n",
    "    \n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                  image_np_with_detections,\n",
    "                  detections['detection_boxes'][0].numpy(),\n",
    "                  (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
    "                  detections['detection_scores'][0].numpy(),\n",
    "                  category_index,\n",
    "                  use_normalized_coordinates=True, # Needs to be true cause otherwise boxes go out of range\n",
    "                  max_boxes_to_draw=3, # Minimized to 10 because otherwise we might have troubles \n",
    "                  min_score_thresh=threshold, # Minimized the score, as for now it seems to be too confident over Adidas\n",
    "                  agnostic_mode=False)\n",
    "    \n",
    "    df_general_annot = pd.read_csv(f\"{current_working_directory}/inference_PROD/ANNOTATIONS&PREDICTIONS/annotations.csv\")\n",
    "    simple_filename = image.split(\"\\\\\")[-1]\n",
    "    df_true_annot = df_general_annot[df_general_annot[\"filename\"]==simple_filename]\n",
    "\n",
    "    plt.figure(figsize=(12,16))\n",
    "\n",
    "    for index, row in df_true_annot.iterrows():\n",
    "        # Create a Rectangle patch\n",
    "        plt.scatter(row[\"xmin\"], row[\"ymin\"])\n",
    "        plt.scatter(row[\"xmin\"], row[\"ymax\"])\n",
    "        plt.scatter(row[\"xmax\"], row[\"ymin\"])\n",
    "        plt.scatter(row[\"xmax\"], row[\"ymax\"])\n",
    "\n",
    "    plt.imshow(image_np_with_detections)\n",
    "    plt.savefig(f\"{current_working_directory}/inference_PROD/COMPARE/{simple_filename}\")\n",
    "    plt.close()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/Users/rebec/Documents/GitHub/ObjectRecognition/LogoDetection_DSBAProject/inference_PROD/INFERENCE_DIR\\myfilename.jpg\n",
      "         filename  width  height   class  xmin  ymin  xmax  ymax  area\n",
      "0  myfilename.jpg    512     512  Adidas    91   247   198   331  8988\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "\n",
    "images_list = list(TEST_IMAGE_PATHS)\n",
    "for img in images_list:\n",
    "    print(img)\n",
    "    print_true_predicted(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40a8aae49d8ead891f177a9aa92f4d86d5628cb1b4814a86ede39a8e1ef554b8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
